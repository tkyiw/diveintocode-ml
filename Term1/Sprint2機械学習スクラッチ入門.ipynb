{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# このSprintについて\n",
    "\n",
    "### Sprintの目的\n",
    "- 機械学習スクラッチの準備をする\n",
    "\n",
    "### どのように学ぶか\n",
    "- 今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。  \n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8, random_state=None, shuffle=True, stratify=None):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import math\n",
    "    \n",
    "    # シードを設定して乱数を出力\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # X, yを結合\n",
    "    data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    # 行数, 列数\n",
    "    row, col = data.shape\n",
    "    \n",
    "    # trainのサンプル数\n",
    "    num = math.ceil(row * train_size)\n",
    "    \n",
    "    #-----------------------------------------------------------\n",
    "    \n",
    "    # shuffleがTrueならindexをシャッフルする。\n",
    "    if shuffle is True:\n",
    "        np.random.shuffle(data)\n",
    "    \n",
    "    # 引数stratifyに均等に分割させたいデータの指定がある。\n",
    "    if stratify is not None:\n",
    "        \n",
    "        # 結合用のarray\n",
    "        train_mod = np.ones((0, col))\n",
    "        test_mod = np.ones((0, col))\n",
    "        \n",
    "        # ユニークな要素の個数・頻度をカウント\n",
    "        uniques, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        for u, c in zip(uniques, counts):\n",
    "            # uの要素を含む行をtrain_size分train_modに結合\n",
    "            mod1 = data[data[:, -1]==u][:math.ceil(c*train_size)]\n",
    "            train_mod = np.concatenate((train_mod, mod1),axis=0)\n",
    "            # uの要素を含む行のtrain_size分移行をtest_modに結合\n",
    "            mod2 = data[data[:, -1]==u][math.ceil(c*train_size):]\n",
    "            test_mod = np.concatenate((test_mod, mod2), axis=0)\n",
    "            \n",
    "        X_train, X_test = train_mod[:, :-1], test_mod[:, :-1]\n",
    "        y_train, y_test = train_mod[:, -1], test_mod[:, -1]\n",
    "        \n",
    "        # ユニークな要素が分割できない時はエラーを出力\n",
    "        if len(np.unique(y_test)) < len(uniques):\n",
    "            raise ValueError('yのクラス数が足りません。')\n",
    "\n",
    "    else:\n",
    "        X_train, X_test = data[:num, :-1], data[num:, :-1]\n",
    "        y_train, y_test = data[:num, -1], data[num:, -1]  \n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類問題\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "\n",
    "# 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アイリスデータ\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# インスタンスを生成\n",
    "data = load_iris()\n",
    "\n",
    "# データをDataFrame型でXに格納する。\n",
    "X = pd.DataFrame(data.data, columns=['sepal_length',\n",
    "                                     'sepal_width',\n",
    "                                     'petal_length',\n",
    "                                     'petal_width'])\n",
    "# 目的変数も同様にyに格納する。\n",
    "y = pd.DataFrame(data.target, columns=['Species'])\n",
    "\n",
    "# X,yを結合\n",
    "df = pd.concat([X, y], axis=1) # axis=1 列方向に結合\n",
    "\n",
    "# 2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。virgicolorとvirginica\n",
    "df = df[df['Species']!=0]\n",
    "df['Species'] -= 1 # ({0: virgicolor, 1: virginica})\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# 訓練データと検証データに分割\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df[['Species']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 学習\n",
    "sgdc = SGDClassifier(loss='log', random_state=0)\n",
    "sgdc.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "sgdc_pred = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1],\n",
       "       [1, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価\n",
    "confusion_matrix(y_test, sgdc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1作成コード\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# 学習\n",
    "svc = SVC(random_state=0)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "svc_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0],\n",
       "       [ 0, 50]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価\n",
    "confusion_matrix(y_test, svc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決定木 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット2作成コード\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 学習\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "dt_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価\n",
    "confusion_matrix(y_test, dt_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰問題\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n",
    "\n",
    "# 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('../kaggledata/train.csv')\n",
    "X = train[['GrLivArea', 'YearBuilt']].values\n",
    "y = train[['SalePrice']].values\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# 学習\n",
    "sgdr = SGDRegressor(random_state=0, loss='huber')\n",
    "sgdr.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "sgdr_pred = sgdr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5093111780643031"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価 R^2\n",
    "sgdr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([277046, 183364, 146077, 228136, 135285])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sgdr_pred[:5].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205000,  96500, 130000, 250000, 133900])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
