{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.このSprintについて\n",
    "\n",
    "Sprintの目的\n",
    "- 機械学習分野の論文から有益な情報を引き出せるようにする\n",
    "- これまで扱ってきた領域の論文から新たな知識を得る\n",
    "\n",
    "どのように学ぶか\n",
    "- ある論文に対しての問題に答えていくことで、読むポイントを学んでいきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.論文読解\n",
    "\n",
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
    "\n",
    "\n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "\n",
    "[https://arxiv.org/pdf/1506.01497.pdf](https://arxiv.org/pdf/1506.01497.pdf)\n",
    "\n",
    "\n",
    "## 問題\n",
    "それぞれについてJupyter Notebookにマークダウン形式で記述してください。\n",
    "\n",
    "\n",
    "(1) 物体検出の分野にはどういった手法が存在したか。\n",
    "\n",
    "\n",
    "(2) Fasterとあるが、どういった仕組みで高速化したのか。\n",
    "\n",
    "\n",
    "(3) One-Stageの手法とTwo-Stageの手法はどう違うのか。\n",
    "\n",
    "\n",
    "(4) RPNとは何か。\n",
    "\n",
    "\n",
    "(5) RoIプーリングとは何か。\n",
    "\n",
    "\n",
    "(6) Anchorのサイズはどうするのが適切か。\n",
    "\n",
    "\n",
    "(7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
    "\n",
    "\n",
    "(8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。\n",
    "\n",
    "\n",
    "## 条件\n",
    "- 答える際は論文のどの部分からそれが分かるかを書く。\n",
    "- 必要に応じて先行研究（引用されている論文）も探しにいく。最低2つは他の論文を利用して回答すること。\n",
    "- 論文の紹介記事を見ても良い。ただし、答えは論文内に根拠を探すこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 物体検出の分野にはどういった手法が存在したか。\n",
    ">Object proposal methods were adopted as external modules independent of the detectors (e.g., Selective Search [4] object detectors, RCNN [5], and Fast R-CNN [2]).\n",
    "\n",
    "RCNN、Fast R-CNNなどの手法が存在する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Fasterとあるが、どういった仕組みで高速化したのか。\n",
    ">In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.\n",
    "\n",
    "物体領域候補の抽出をCNNで行うRPNを導入したことで高速化した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">OverFeat is a one-stage, class-specific detection pipeline, and ours is a two-stage cascade consisting of class-agnostic proposals and class-specific detections.\n",
    "\n",
    "1ステージはクラス固有の検出パイプラインであり、2ステージはクラスにとらわれない提案とクラス固有の検出で構成される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) RPNとは何か。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">To this end, we introduce novel Region Proposal Networks (RPNs) that share convolutional layers with state-of-the-art object detection networks [1], [2]. By sharing convolutions at test-time, the marginal cost for computing proposals is small (e.g., 10ms per image).\n",
    "\n",
    "最新のオブジェクト検出ネットワークと畳み込み層を共有する新しい領域提案ネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) RoIプーリングとは何か"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[2] R. Girshick, “Fast R-CNN,” in IEEE International Conference on Computer Vision (ICCV), 2015.  \n",
    "The RoI pooling layer uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of H × W (e.g., 7 × 7), where H and W are layer hyper-parameters that are independent of any particular RoI. In this paper, an RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (r, c, h, w) that specifies its top-left corner (r, c) and its height and width (h, w).\n",
    "\n",
    "RoIプーリングを施すことによって、有効な関心領域内のフィーチャをH×Wの固定空間範囲（たとえば、7×7）の小さなフィーチャマップに変換する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3つのスケールと3つのアスペクト比（69.9％）を使用するのが適切である。\n",
    "\n",
    "![あ](https://gyazo.com/07f9cad19710f8a0fa44a9fdf4fd0912.gng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASCAL VOC 2007、PASCAL VOC 2012、MS COCOを使用し、maPが向上した。\n",
    "\n",
    "![あd](https://gyazo.com/4fa79028fc4c6186bf4bf3eb02807d5b.gng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
