{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60 51 51 63]\n",
      " [51 58 53 46]\n",
      " [51 51 42 67]]\n",
      "[[60 51 51 63]\n",
      " [51 58 53 46]\n",
      " [51 51 42 67]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(0,10,(3,4,3,4))\n",
    "# solution by passing a tuple of axes (introduced in numpy 1.7.0)\n",
    "sum = A.sum(axis=(-2,-1))\n",
    "print(sum)\n",
    "# solution by flattening the last two dimensions into one\n",
    "# (useful for functions that don't accept tuples for axis argument)\n",
    "sum = A.reshape(A.shape[:-2] + (-1,)).sum(axis=-1)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 3, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56, 46, 45, 67],\n",
       "       [53, 53, 53, 41],\n",
       "       [54, 73, 54, 49]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 3, 0, 3],\n",
       "       [6, 9, 4, 7],\n",
       "       [4, 5, 8, 5]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[6, 3, 0, 3],\n",
       "         [6, 9, 4, 7],\n",
       "         [4, 5, 8, 5]],\n",
       "\n",
       "        [[2, 0, 3, 7],\n",
       "         [8, 7, 3, 2],\n",
       "         [8, 3, 3, 5]],\n",
       "\n",
       "        [[1, 9, 4, 4],\n",
       "         [5, 6, 1, 2],\n",
       "         [1, 7, 7, 4]],\n",
       "\n",
       "        [[9, 1, 3, 9],\n",
       "         [2, 1, 9, 2],\n",
       "         [9, 9, 4, 5]]],\n",
       "\n",
       "\n",
       "       [[[2, 4, 1, 2],\n",
       "         [6, 5, 6, 1],\n",
       "         [9, 9, 0, 6]],\n",
       "\n",
       "        [[8, 4, 8, 1],\n",
       "         [8, 1, 6, 8],\n",
       "         [8, 1, 5, 0]],\n",
       "\n",
       "        [[6, 9, 0, 7],\n",
       "         [0, 5, 6, 2],\n",
       "         [0, 7, 6, 5]],\n",
       "\n",
       "        [[8, 1, 1, 9],\n",
       "         [0, 4, 2, 4],\n",
       "         [0, 4, 8, 5]]],\n",
       "\n",
       "\n",
       "       [[[3, 2, 8, 7],\n",
       "         [2, 2, 7, 4],\n",
       "         [5, 6, 4, 1]],\n",
       "\n",
       "        [[4, 1, 5, 8],\n",
       "         [8, 2, 0, 5],\n",
       "         [4, 5, 2, 7]],\n",
       "\n",
       "        [[0, 5, 7, 1],\n",
       "         [2, 4, 3, 2],\n",
       "         [4, 8, 0, 6]],\n",
       "\n",
       "        [[7, 7, 5, 9],\n",
       "         [6, 7, 6, 2],\n",
       "         [2, 9, 7, 0]]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [11, 12,  0, 14, 15],\n",
       "        [16, 17, 18, 19, 20],\n",
       "        [21, 22, 23, 24, 25]],\n",
       "\n",
       "       [[26, 27, 28, 29, 30],\n",
       "        [31, 32, 33, 34, 35],\n",
       "        [36, 37,  0, 39, 40],\n",
       "        [41, 42, 43, 44, 45],\n",
       "        [46, 47, 48, 49, 50]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(1, 51).reshape(2, 5, 5)\n",
    "a[:, 2:3, 2:3] = 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 30])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(1, 11).reshape(-1, 2)\n",
    "b.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15,  40,  52,  90, 115],\n",
       "       [140, 165, 152, 215, 240]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([155, 205, 204, 305, 355])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b.astype('float64')\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.W.ndim < 4:\n",
    "            FN, C, FH = self.W.shape\n",
    "            self.W = self.W.reshape(FN, C, 1, FH)\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        if x.ndim < 4:\n",
    "            C, H = x.shape\n",
    "            x = x.reshape(1, C, 1, H)\n",
    "        N, C, H, W = x.shape\n",
    "        self.N, self.C, self.H, self.w = N, C, H, W\n",
    "        \n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        \n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.reshape(self.N, self.C, self.H, -1)\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        self = self.update(self)\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "    def update(self, layer):\n",
    "        layer.W -= 1 * layer.dW\n",
    "        layer.b -= 1 * layer.db\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[16., 22.]],\n",
       "\n",
       "        [[17., 23.]],\n",
       "\n",
       "        [[18., 24.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes = Convolution(w, b)\n",
    "tes.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 61., 120., 120.,  59.]],\n",
       "\n",
       "        [[ 61., 120., 120.,  59.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes.backward(tes.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        # 最適化手法\n",
    "        self.optimizer = optimizer\n",
    "        # AdaGradの初期値\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        if X.ndim >= 4:\n",
    "            fn, c, fh, hw = X.shape\n",
    "            X = X.reshape(c, hw)\n",
    "        self.Z = X\n",
    "        print(X.shape)\n",
    "        print(self.W.shape)\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    '''\n",
    "    AdaGradによる最適化\n",
    "    '''\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr # 学習率\n",
    "    \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 # 0で除算してしまうのを防ぐための値\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    '''\n",
    "    ReLU関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        A = self.A.reshape(dZ.shape)\n",
    "        dA = dZ * np.where(A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    '''\n",
    "    ソフトマックス関数と交差エントロピー誤差\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "        y : ラベル  ndarray, shape (batch_size,)\n",
    "            入力\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        loss : 交差エントロピー誤差\n",
    "        \"\"\"\n",
    "        dA = Z - y\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out = x.reshape(N, -1)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout.reshape(self.x.shape)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier():\n",
    "    \"\"\"\n",
    "    3層からなるニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, FN=20, C=1, F=4, epoch=1, optimizer=AdaGrad, initializer=HeInitializer, activater=Relu, verbose=False,):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = 20 # バッチサイズ\n",
    "        self.n_features = 784 # 特徴量の数\n",
    "        self.n_nodes1 = 400 # 1層目のノード数\n",
    "        self.n_nodes2 = 200 # 2層目のノード数\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        self.sigma = 0.02 # ガウス分布の標準偏差\n",
    "        self.lr = 0.5 # 学習率\n",
    "        self.epoch = epoch # エポック数\n",
    "        self.optimizer = optimizer # 最適化手法\n",
    "        self.initializer = initializer # 初期化方法\n",
    "        self.activater = activater # 活性化関数\n",
    "        self.FN = FN\n",
    "        self.C = C\n",
    "        self.F = F\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.loss_train = [] # 学習データのloss記録用\n",
    "        self.loss_val = [] # 検証データのloss記録用\n",
    "        \n",
    "        # 最適化手法を選択\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        \n",
    "        # 初期化と活性化関数を定義\n",
    "        w = self.sigma * np.random.randn(self.FN, self.C, self.F)\n",
    "        b = self.sigma * np.random.randn(self.FN,)\n",
    "        self.cv = Convolution(w, b)\n",
    "        self.activation_cv = self.activater()\n",
    "        self.FC = FC(781, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation_fc = SoftmaxWithLoss()\n",
    "        \n",
    "        # 学習\n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "\n",
    "                # フォワード\n",
    "                print(mini_X.shape)\n",
    "                A1 = self.cv.forward(mini_X)\n",
    "                print(A1.shape)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "                print(Z1.shape)\n",
    "                A2 = self.FC.forward(Z1)\n",
    "                print(A2.shape)\n",
    "                Z2 = self.activation_fc.forward(A2)\n",
    "                print(Z2.shape)\n",
    "\n",
    "                # バックワード\n",
    "                dA2, loss = self.activation_fc.backward(Z2, mini_y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dA1 = self.activation_cv.backward(dZ2)\n",
    "                dZ1 = self.cv.backward(dA1)\n",
    "            \n",
    "#             # エポックごとに交差エントロピー誤差を記録\n",
    "#             if self.verbose:\n",
    "#                 A1 = self.FC1.forward(X)\n",
    "#                 Z1 = self.activation1.forward(A1)\n",
    "#                 A2 = self.FC2.forward(Z1)\n",
    "#                 Z2 = self.activation2.forward(A2)\n",
    "#                 A3 = self.FC3.forward(Z2)\n",
    "#                 Z3 = self.activation3.forward(A3)            \n",
    "#                 self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
    "                \n",
    "#                 if X_val is not None:\n",
    "#                     A1 = self.FC1.forward(X_val)\n",
    "#                     Z1 = self.activation1.forward(A1)\n",
    "#                     A2 = self.FC2.forward(Z1)\n",
    "#                     Z2 = self.activation2.forward(A2)\n",
    "#                     A3 = self.FC3.forward(Z2)\n",
    "#                     Z3 = self.activation3.forward(A3)            \n",
    "#                     self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.cv.forward(X)\n",
    "        Z1 = self.activation_cv.forward(A1)\n",
    "        A2 = self.FC.forward(Z1)\n",
    "        Z2 = self.activation_fc.forward(A2)\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# データセット読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 標準化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier():\n",
    "    \"\"\"\n",
    "    3層からなるニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch=1, optimizer=AdaGrad, initializer=HeInitializer, activater=Relu, verbose=False,):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = 20 # バッチサイズ\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        self.sigma = 0.02 # ガウス分布の標準偏差\n",
    "        self.lr = 0.1 # 学習率\n",
    "        self.epoch = epoch # エポック数\n",
    "        self.optimizer = optimizer # 最適化手法\n",
    "        self.initializer = initializer # 初期化方法\n",
    "        self.activater = activater # 活性化関数\n",
    "        self.FN = 3\n",
    "        self.C = 1\n",
    "        self.FH = 3\n",
    "        self.FW = 3\n",
    "        self.F = 3\n",
    "        self.pool_h = 2\n",
    "        self.pool_w = 2\n",
    "        self.pad = 0\n",
    "        self.stride = 1\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.loss_train = [] # 学習データのloss記録用\n",
    "        self.loss_val = [] # 検証データのloss記録用\n",
    "        \n",
    "        # 全結合層へ流れるnode数を取得\n",
    "#         out_h, out_w = self.out_size(28, 28, self.pad, self.FH, self.FW, self.stride)\n",
    "#         out_h, out_w = self.out_size(out_h, out_w, self.pad, self.pool_h, self.pool_w, self.pool_h)\n",
    "#         fc_nodes = self.FN * out_h * out_w\n",
    "        \n",
    "        # 最適化手法を選択\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        \n",
    "        # 重みとバイアスの初期値\n",
    "        w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
    "        b = self.sigma * np.random.randn(self.FN,)\n",
    "        \n",
    "        # インスタンス化\n",
    "        self.cv = Conv1d(w, b)\n",
    "        self.activation_cv = self.activater()\n",
    "#         self.pl = MaxPool2D(self.pool_h, self.pool_w)\n",
    "        self.fl = Flatten()\n",
    "        self.FC = FC(781, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation_fc = SoftmaxWithLoss()\n",
    "        \n",
    "        # 学習\n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "\n",
    "                # フォワード\n",
    "                A1 = self.cv.forward(mini_X)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "#                 P1 = self.pl.forward(Z1)\n",
    "                F1 = self.fl.forward(Z1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.activation_fc.forward(A2)\n",
    "\n",
    "                # バックワード\n",
    "                dA2, loss = self.activation_fc.backward(Z2, mini_y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dF1 = self.fl.backward(dZ2)\n",
    "#                 dP1 = self.pl.backward(dF1)\n",
    "                dA1 = self.activation_cv.backward(dF1)\n",
    "                dZ1 = self.cv.backward(dA1)\n",
    "            \n",
    "            # エポックごとに交差エントロピー誤差を記録\n",
    "#             if self.verbose:\n",
    "#                 A1 = self.cv.forward(X)\n",
    "#                 Z1 = self.activation_cv.forward(A1)\n",
    "#                 P1 = self.pl.forward(Z1)\n",
    "#                 F1 = self.fl.forward(P1)\n",
    "#                 A2 = self.FC.forward(F1)\n",
    "#                 Z2 = self.activation_fc.forward(A2)  \n",
    "#                 self.loss_train.append(self.activation_fc.backward(Z2, y)[1])\n",
    "                \n",
    "#                 if X_val is not None:\n",
    "#                     A1 = self.cv.forward(X_val)\n",
    "#                     Z1 = self.activation_cv.forward(A1)\n",
    "#                     P1 = self.pl.forward(Z1)\n",
    "#                     F1 = self.fl.forward(P1)\n",
    "#                     A2 = self.FC.forward(F1)\n",
    "#                     Z2 = self.activation_fc.forward(A2)         \n",
    "#                     self.loss_val.append(self.activation_fc.backward(Z2, y_val)[1])\n",
    "                    \n",
    "    def out_size(self, H, W, P, FH, FW, S):\n",
    "        out_h = (H + 2 * P - FH) // S + 1\n",
    "        out_w = (W + 2 * P - FW) // S + 1\n",
    "        return out_h, out_w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.cv.forward(X)\n",
    "        Z1 = self.activation_cv.forward(A1)\n",
    "        P1 = self.pl.forward(Z1)\n",
    "        F1 = self.fl.forward(P1)\n",
    "        A2 = self.FC.forward(F1)\n",
    "        Z2 = self.activation_fc.forward(A2)\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 784)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (781,80) and (4,20) not aligned: 80 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-07d06134ed53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratch1dCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-929b193f8e18>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# フォワード\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f337746c245a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcol_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_W\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (781,80) and (4,20) not aligned: 80 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "tes = Scratch1dCNNClassifier()\n",
    "tes.fit(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
