{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.このSprintについて\n",
    "\n",
    "Sprintの目的\n",
    "- スクラッチを通してニューラルネットワークの基礎を理解する\n",
    "- 画像データの扱い方を知る\n",
    "\n",
    "どのように学ぶか\n",
    "- スクラッチで単純なニューラルネットワークを実装した後、学習と検証を行なっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.MNISTデータセット\n",
    "\n",
    "ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用します。各種ライブラリやサイトからダウンロードできますが、ここでは深層学習フレームワークのKerasを用います。以下のコードを実行すればデータセットをダウンロードし、展開まで行えます。\n",
    "\n",
    "\n",
    "### 《データセットをダウンロードするコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《MNISTとは？》\n",
    "\n",
    "\n",
    "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベルが含まれています。\n",
    "\n",
    "\n",
    "### 《画像データとは？》\n",
    "\n",
    "\n",
    "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。\n",
    "\n",
    "\n",
    "### データセットの確認\n",
    "どういったデータなのかを見てみます。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各データは28×28ピクセルの白黒画像です。\n",
    "\n",
    "\n",
    "### 平滑化\n",
    "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。全てのピクセルが一列になっていることを、 平滑化（flatten） してあるという風に表現します。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《補足》\n",
    "\n",
    "\n",
    "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしもカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像データの可視化\n",
    "画像データを可視化します。plt.imshowに渡します。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《発展的話題》\n",
    "\n",
    "\n",
    "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、plt.imshowはより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどと全く同じ風に表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは、自動的に値を0〜255の整数に変換して処理するように作られているからです。uint8型であっても最小値が0、最大値が255でない場合には色合いがおかしくなります。それを防ぐためには次のように引数を入れてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1118cf790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理\n",
    "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。以下のコードで変換可能です。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.ニューラルネットワークスクラッチ\n",
    "\n",
    "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。\n",
    "\n",
    "\n",
    "### 《雛形》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.0001, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = lr #学習率\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.batch_size = 20 # バッチサイズ\n",
    "        self.n_features = 784 # 特徴量の数\n",
    "        self.n_nodes1 = 400 # 1層目のノード数\n",
    "        self.n_nodes2 = 200 # 2層目のノード数\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        self.sigma = 2 # ガウス分布の標準偏差\n",
    "        self.error_log = []\n",
    "        \n",
    "        # 重みの初期値\n",
    "        self.W1 = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "\n",
    "        # バイアスの初期値\n",
    "        self.B1 = self.sigma * np.random.randn(1, self.n_nodes1)\n",
    "        self.B2 = self.sigma * np.random.randn(1, self.n_nodes2)\n",
    "        self.B3 = self.sigma * np.random.randn(1, self.n_output)\n",
    "        \n",
    "        # ミニバッチ処理\n",
    "        get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "        for mini_X_train, mini_y_train in get_mini_batch:\n",
    "            \n",
    "            #フォワードプロパゲーション\n",
    "            self.forward(mini_X_train)\n",
    "            \n",
    "            self.error_log.append(self.cross_entropy_error(mini_y_train, self.Z3))\n",
    "            \n",
    "            # バックプロパゲーション\n",
    "            # ３層目\n",
    "            dA3 = self.Z3 - mini_y_train\n",
    "            dB3 = np.sum(dA3, axis=0)\n",
    "            dW3 = self.Z2.T @ dA3\n",
    "            dZ2 = dA3 @ self.W3.T\n",
    "            # ２層目\n",
    "            dA2 = dZ2 * (1 - self.tanh_function(self.A2)**2)\n",
    "            dB2 = np.sum(dA2, axis=0)\n",
    "            dW2 = self.Z1.T @ dA2\n",
    "            dZ1 = dA2 @ self.W2.T\n",
    "            # １層目\n",
    "            dA1 = dZ1 * (1 - self.tanh_function(self.A1)**2)\n",
    "            dB1 = np.sum(dA1, axis=0)\n",
    "            dW1 = mini_X_train.T @ dA1\n",
    "            # 更新\n",
    "            self.W3 -= self.lr * dW3\n",
    "            self.B3 -= self.lr * dB3\n",
    "            self.W2 -= self.lr * dW2\n",
    "            self.B2 -= self.lr * dB2\n",
    "            self.W1 -= self.lr * dW1\n",
    "            self.B1 -= self.lr * dB1\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # フォワードプロパゲーション\n",
    "        # １層目\n",
    "        self.A1 = X @ self.W1 + self.B1\n",
    "        self.Z1 = self.tanh_function(self.A1)\n",
    "        # ２層目\n",
    "        self.A2 = self.Z1 @ self.W2 + self.B2\n",
    "        self.Z2 = self.tanh_function(self.A2)\n",
    "        # ３層目\n",
    "        self.A3 = self.Z2 @ self.W3 + self.B3\n",
    "        self.Z3 = self.softmax_function(self.A3)\n",
    "    \n",
    "    def sigmoid_function(self, A):\n",
    "        '''\n",
    "        シグモイド関数\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-A))\n",
    "\n",
    "    def tanh_function(self, A):\n",
    "        '''\n",
    "        ハイパボリックタンジェント関数\n",
    "        '''\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def softmax_function(self, A):\n",
    "        '''\n",
    "        ソフトマックス関数\n",
    "        '''\n",
    "        return np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "\n",
    "    def cross_entropy_error(self, y, Z):\n",
    "        '''\n",
    "        交差エントロピー誤差\n",
    "        '''\n",
    "        L = - np.sum(y * np.log(Z)) / self.batch_size\n",
    "        return L\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        self.forward(X)\n",
    "        return np.argmax(self.Z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ処理\n",
    "これまでの機械学習スクラッチでは、全てのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。\n",
    "\n",
    "\n",
    "今回はバッチサイズを20とします。今回使う訓練データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練データを一度全て見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。\n",
    "\n",
    "\n",
    "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。\n",
    "\n",
    "\n",
    "### 《コード》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクラスをインスタンス化し、for文を使うことでミニバッチが取り出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([9, 1, 6, 6, 7, 1, 8, 9, 0, 2, 5, 7, 5, 8, 1, 7, 0, 8, 3, 5],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__getitem__や__next__は__init__と同じ特殊メソッドの一種です。\n",
    "\n",
    "\n",
    "### 学習\n",
    "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。\n",
    "\n",
    "\n",
    "### 《サンプルコード》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # バッチサイズ\n",
    "n_features = 784 # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "sigma = 0.01 # ガウス分布の標準偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "B1 = sigma * np.random.randn(1, n_nodes1)\n",
    "\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "B2 = sigma * np.random.randn(1, n_nodes2)\n",
    "\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "B3 = sigma * np.random.randn(1, n_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「1層目」\n",
    "$$\n",
    "A_1 = X \\cdot W_1 + B_1\n",
    "$$\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)  \n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)  \n",
    "$B_1$ : 1層目のバイアス (n_nodes1,)  \n",
    "$A_1$ : 出力 (batch_size, n_nodes1)  \n",
    "\n",
    "\n",
    "「1層目の活性化関数」\n",
    "$$\n",
    "Z_1 = f(A_1)\n",
    "$$\n",
    "\n",
    "$f()$ : 活性化関数\n",
    "\n",
    "\n",
    "$Z_1$ 出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "「2層目」\n",
    "$$\n",
    "A_2 = Z_1 \\cdot W_2 + B_2\n",
    "$$\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)  \n",
    "$B_2$ : 2層目のバイアス (n_nodes2,)  \n",
    "$A_2$ : 出力 (batch_size, n_nodes2)  \n",
    "\n",
    "\n",
    "「2層目の活性化関数」\n",
    "$$\n",
    "Z_2 = f(A_2)\n",
    "$$\n",
    "\n",
    "$f()$ : 活性化関数\n",
    "\n",
    "\n",
    "$Z_2$ 出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "「3層目（出力層）」\n",
    "$$\n",
    "A_3 = Z_2 \\cdot W_3 + B_3\n",
    "$$\n",
    "\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)  \n",
    "$B_3$ : 3層目のバイアス (n_output,)  \n",
    "$A_3$ : 出力 (batch_size, n_output)  \n",
    "\n",
    "\n",
    "「3層目の活性化関数」\n",
    "$$\n",
    "Z_3 = softmax(A_3)\n",
    "$$\n",
    "\n",
    "\n",
    "$softmax()$ : ソフトマックス関数  \n",
    "$Z_3$ 出力 (batch_size, n_output)  \n",
    "$Z_3$ は各ラベル（0〜9）に対する確率の配列である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数（フォワードプロバゲーション）\n",
    "活性化関数を作成し、フォワードプロパゲーションの中で使用します。切り替えられるように実装することを推奨しますが、片方でも構いません。\n",
    "\n",
    "\n",
    "「シグモイド関数」\n",
    "\n",
    "$$\n",
    "f(Z) = sigmoid(A) = \\frac{1}{1+exp(-A)}\n",
    "$$\n",
    "\n",
    "「ハイパボリックタンジェント関数」\n",
    "\n",
    "\n",
    "次の数式で表されますが、np.tanhひとつで実現できます。\n",
    "$$\n",
    "f(Z) = tanh(A) = \\frac{exp(A) - exp(-A)}{exp(A) + exp(-A)}\n",
    "$$\n",
    "\n",
    "\n",
    "＊現在ではこれらの代わりにReLUと呼ばれる活性化関数が一般的です。次のSprintで扱います。\n",
    "\n",
    "## ソフトマックス関数\n",
    "ソフトマックス関数を作成し、フォワードプロパゲーションの中で使用します。これも活性化関数の一種ですが、多クラス分類の出力層で使われる特性上、区別して扱われることが多いです。\n",
    "\n",
    "\n",
    "次の数式です。\n",
    "$$\n",
    "Z_{3\\_k} = \\frac{exp(A_{3\\_k})}{\\sum_{i=1}^{n_c}exp(A_{3\\_i})}\n",
    "$$\n",
    "\n",
    "$Z_{3_k}$ : $k$ 番目のクラスの確率ベクトル (batch_size,)\n",
    "\n",
    "\n",
    "$A_{3_k}$ : $k$ 番目のクラスにあたる前の層からのベクトル (batch_size,)\n",
    "\n",
    "\n",
    "$n_c$ : クラスの数、n_output。今回のMNISTでは10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(A):\n",
    "    return 1 / (1 + np.exp(-A))\n",
    "\n",
    "def tanh_function(A):\n",
    "    return np.tanh(A)\n",
    "\n",
    "def softmax_function(A):\n",
    "    return np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ\n",
    "get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=20)\n",
    "for X, y in get_mini_batch:\n",
    "    X = X\n",
    "    y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# １層目\n",
    "A1 = X @ W1 + B1\n",
    "Z1 = sigmoid_function(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ２層目\n",
    "A2 = Z1 @ W2 + B2\n",
    "Z2 = sigmoid_function(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ３層目\n",
    "A3 = Z2 @ W3 + B3\n",
    "Z3 = softmax_function(A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z3.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。\n",
    "$$\n",
    "L = - \\frac{1}{n_b}\\sum_{j}^{n_b}\\sum_{k}^{n_c}y_{jk} log(z_{3\\_jk})\n",
    "$$\n",
    "\n",
    "\n",
    "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）  \n",
    "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）  \n",
    "$n_{b}$ : バッチサイズ、batch_size  \n",
    "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）  \n",
    "サンプル1つあたりの誤差が求まります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, Z):\n",
    "    L = - np.sum(y * np.log(Z)) / batch_size\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.308509661692779"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y, Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 $W_i$ と $B_i$ に対し、更新後の $W_i^{\\prime}$ と $B_i^{\\prime}$ は次の数式で求められます。\n",
    "\n",
    "$$\n",
    "W_i^{\\prime} = W_i - \\alpha \\frac{\\partial L}{\\partial W_i}\n",
    "$$\n",
    "$$\n",
    "B_i^{\\prime} = B_i - \\alpha \\frac{\\partial L}{\\partial B_i}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）  \n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。\n",
    "\n",
    "\n",
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。\n",
    "\n",
    "\n",
    "「3層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_3} = Z_{3} - Y\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_3} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{3\\_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_3} = Z_{2}^{T}\\cdot \\frac{\\partial L}{\\partial A_3}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \\cdot W_3^T\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (batch_size, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{3_j}}$ : j番目のサンプルの$A_3$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Y$ : 正解ラベル (batch_size, n_output)\n",
    "\n",
    "\n",
    "$Z_{2}$ : 2層目の活性化関数の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
    "\n",
    "「2層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot \\{1-tanh^2(A_{2})\\}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_2} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{2\\_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} = Z_{1}^T \\cdot \\frac{\\partial L}{\\partial A_2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \\cdot W_2^T\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{2_j}}$ : j番目のサンプルの$A_2$ に関する損失 $L$ の勾配 (n_nodes2,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$A_2$ : 2層目の出力 (batch_size, n_nodes2)\n",
    "\n",
    "\n",
    "$Z_{1}$ : 1層目の活性化関数の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
    "\n",
    "\n",
    "「1層目」\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot \\{1-tanh^2(A_{1})\\}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial B_1} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{1\\_j}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial A_1}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial A_{1_j}}$ : j番目のサンプルの$A_1$ に関する損失 $L$ の勾配 (n_nodes1,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (n_output,)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$A_1$ : 1層目の出力 (batch_size, n_nodes1)\n",
    "\n",
    "\n",
    "$X$ : 特徴量ベクトル (batch_size, n_features)\n",
    "\n",
    "\n",
    "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot  \\{1-sigmoid(A_{2})\\}sigmoid(A_{2})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot  \\{1-sigmoid(A_{1})\\}sigmoid(A_{1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1 #学習率\n",
    "\n",
    "# ３層目\n",
    "dA3 = Z3 - y\n",
    "dB3 = np.sum(dA3, axis=0)\n",
    "dW3 = Z2.T @ dA3\n",
    "dZ2 = dA3 @ W3.T\n",
    "\n",
    "# ２層目\n",
    "dA2 = dZ2 * (1 - tanh_function(A2)**2)\n",
    "dB2 = np.sum(dA2, axis=0)\n",
    "dW2 = Z1.T @ dA2\n",
    "dZ1 = dA2 @ W2.T\n",
    "\n",
    "# １層目\n",
    "dA1 = dZ1 * (1 - tanh_function(A1)**2)\n",
    "dB1 = np.sum(dA1, axis=0)\n",
    "dW1 = X.T @ dA1\n",
    "\n",
    "# 更新\n",
    "W3 -= lr * dW3\n",
    "B3 -= lr * dB3\n",
    "\n",
    "W2 -= lr * dW2\n",
    "B2 -= lr * dB2\n",
    "\n",
    "W1 -= lr * dW1\n",
    "B1 -= lr * dB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】推定\n",
    "推定を行うメソッドを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Z3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tes = ScratchSimpleNeuralNetrowkClassifier()\n",
    "tes.fit(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 6, ..., 5, 1, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tes.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1104"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.12916826803477,\n",
       " 43.6801810787193,\n",
       " 36.93277610121839,\n",
       " 42.26450609695467,\n",
       " 40.59511172804071,\n",
       " 51.503073055978426,\n",
       " 43.268024468390706,\n",
       " 30.82836069758481,\n",
       " 42.8967164572921,\n",
       " 55.32418396169258,\n",
       " 47.82283313664162,\n",
       " 42.41409808689859,\n",
       " 46.40361518710552,\n",
       " 44.66744532212292,\n",
       " 40.74665425302226,\n",
       " 46.110402887494516,\n",
       " 42.062187731540384,\n",
       " 44.72474997813866,\n",
       " 50.35563808153389,\n",
       " 35.78720356279458,\n",
       " 31.08693024021095,\n",
       " 54.9916768988448,\n",
       " 41.222675217996425,\n",
       " 42.33809135639801,\n",
       " 33.630179275186926,\n",
       " 41.659627631561605,\n",
       " 43.61336801928069,\n",
       " 38.3496633895972,\n",
       " 52.919123764279206,\n",
       " 53.232760732339536,\n",
       " 50.65531891296232,\n",
       " 43.670636977599166,\n",
       " 28.513976049806843,\n",
       " 43.50443258670104,\n",
       " 50.78477576415067,\n",
       " 38.436247031755876,\n",
       " 29.451174013643264,\n",
       " 47.21414510066354,\n",
       " 55.29413096797034,\n",
       " 51.91358039599815,\n",
       " 34.83560763810234,\n",
       " 64.72196632516201,\n",
       " 31.56440504394529,\n",
       " 58.794289801819275,\n",
       " 36.94827854904893,\n",
       " 54.22699044555352,\n",
       " 37.38868080023824,\n",
       " 48.59745084200547,\n",
       " 36.975776052705726,\n",
       " 39.16567621327522,\n",
       " 49.77888875211124,\n",
       " 37.02557005545484,\n",
       " 43.505955941713594,\n",
       " 33.153991951904274,\n",
       " 56.456112070360646,\n",
       " 34.04822973323505,\n",
       " 47.663435337249936,\n",
       " 31.144353226498197,\n",
       " 42.91589127749989,\n",
       " 41.04231322593572,\n",
       " 32.27571849994703,\n",
       " 46.87923647101211,\n",
       " 29.280917116643547,\n",
       " 49.414859050923155,\n",
       " 43.76608640941703,\n",
       " 50.50959688345852,\n",
       " 39.7828216689565,\n",
       " 37.27331252576272,\n",
       " 46.14000640933925,\n",
       " 44.40016299453885,\n",
       " 50.7312481797144,\n",
       " 39.66703846754874,\n",
       " 42.349758186189035,\n",
       " 49.315285008046224,\n",
       " 32.299606086827744,\n",
       " 45.33772000794206,\n",
       " 48.182895870513974,\n",
       " 36.793630811053426,\n",
       " 64.81769391892797,\n",
       " 52.879644528679094,\n",
       " 44.14216245575532,\n",
       " 40.920968679752164,\n",
       " 48.75033413456031,\n",
       " 34.19079321813625,\n",
       " 48.243222305101895,\n",
       " 47.94211028200082,\n",
       " 50.462557390269716,\n",
       " 56.12801456727344,\n",
       " 30.06315558795319,\n",
       " 52.31421698990671,\n",
       " 37.740710235615396,\n",
       " 44.90395834011749,\n",
       " 39.12434076150663,\n",
       " 38.713946382268844,\n",
       " 37.03134475595326,\n",
       " 45.64917813910843,\n",
       " 49.8019128556905,\n",
       " 53.71431004810432,\n",
       " 49.77351618778852,\n",
       " 46.43418502044448,\n",
       " 37.40189749934581,\n",
       " 39.628784861371045,\n",
       " 38.27938389242884,\n",
       " 43.943315897094365,\n",
       " 44.1286976412621,\n",
       " 45.75251895665691,\n",
       " 33.147481175444405,\n",
       " 33.731383869716424,\n",
       " 49.19190359797791,\n",
       " 35.859718857476444,\n",
       " 42.347545446250095,\n",
       " 49.29187048817285,\n",
       " 38.52595491607225,\n",
       " 53.25219592465313,\n",
       " 44.50783725482391,\n",
       " 46.10493487457942,\n",
       " 37.21740546553294,\n",
       " 45.02731416176603,\n",
       " 45.759204979580076,\n",
       " 45.141735773941754,\n",
       " 31.457599154390778,\n",
       " 41.93726582032632,\n",
       " 37.78619848393242,\n",
       " 46.36292802928707,\n",
       " 49.80466673131596,\n",
       " 33.004448787179754,\n",
       " 42.01488007297738,\n",
       " 42.48506997265298,\n",
       " 46.709969666951686,\n",
       " 35.63401446325702,\n",
       " 35.8863220479558,\n",
       " 39.243447343349004,\n",
       " 32.87012697680351,\n",
       " 40.473822540955396,\n",
       " 42.00745081782115,\n",
       " 31.201182765166095,\n",
       " 44.28266832769249,\n",
       " 45.74393187107739,\n",
       " 45.229958167383465,\n",
       " 29.664815618785372,\n",
       " 32.14805564188259,\n",
       " 38.87522968399642,\n",
       " 34.09191970891861,\n",
       " 39.47844558365578,\n",
       " 40.31080649824266,\n",
       " 37.04123733350388,\n",
       " 47.962879205114135,\n",
       " 44.983119105161606,\n",
       " 38.90037798624699,\n",
       " 47.650489334623764,\n",
       " 37.31767791776775,\n",
       " 36.0121558186441,\n",
       " 38.31067344729771,\n",
       " 53.10748607745818,\n",
       " 39.888934484107075,\n",
       " 41.9081406822296,\n",
       " 52.34133400200128,\n",
       " 35.075970435953536,\n",
       " 38.612176506445756,\n",
       " 38.55217435945603,\n",
       " 29.381919227098354,\n",
       " 23.873221415472404,\n",
       " 39.161657327739206,\n",
       " 30.232092955648568,\n",
       " 27.482370253324184,\n",
       " 44.96152292358325,\n",
       " 42.317711549313934,\n",
       " 36.081265101118234,\n",
       " 53.549451039098265,\n",
       " 33.34975509915651,\n",
       " 46.54960591059576,\n",
       " 44.209649564073274,\n",
       " 45.45028858484416,\n",
       " 28.81480609344344,\n",
       " 44.423277823695415,\n",
       " 43.866802029090856,\n",
       " 44.85165260807548,\n",
       " 47.25049421323921,\n",
       " 57.329759059861296,\n",
       " 37.0506749653672,\n",
       " 47.020495016411566,\n",
       " 43.9779258321246,\n",
       " 39.251298512402734,\n",
       " 27.970850458661495,\n",
       " 39.04402355470351,\n",
       " 34.49470366577824,\n",
       " 43.44939067586758,\n",
       " 45.40743145944539,\n",
       " 48.34588434622755,\n",
       " 33.05751711953745,\n",
       " 37.53935062516454,\n",
       " 38.53227290001117,\n",
       " 37.42144882005691,\n",
       " 49.63279656222741,\n",
       " 45.402710553625504,\n",
       " 44.82637990754456,\n",
       " 43.37886062785061,\n",
       " 25.74663861196794,\n",
       " 40.155989767371366,\n",
       " 39.9841002478587,\n",
       " 52.917972657275946,\n",
       " 47.701774773313666,\n",
       " 37.01840851167996,\n",
       " 27.139247759409482,\n",
       " 45.74500342879837,\n",
       " 47.442128947457334,\n",
       " 37.175848268771304,\n",
       " 38.8581766104977,\n",
       " 34.5935454156883,\n",
       " 34.89544062497153,\n",
       " 45.54479888850587,\n",
       " 56.31064553498756,\n",
       " 43.35737537792547,\n",
       " 31.33852389365479,\n",
       " 35.38592415009537,\n",
       " 40.362041881576886,\n",
       " 37.610832943098714,\n",
       " 53.635739656550996,\n",
       " 32.469399378393746,\n",
       " 34.37200593286728,\n",
       " 43.348486113049155,\n",
       " 39.46816135598425,\n",
       " 32.37060637746605,\n",
       " 47.640935958394564,\n",
       " 46.442640524614376,\n",
       " 46.09305399582744,\n",
       " 50.32585495085921,\n",
       " 34.72598159259185,\n",
       " 36.29243599862595,\n",
       " 38.707603630153585,\n",
       " 40.60669642960366,\n",
       " 48.854112049065385,\n",
       " 33.410502298600456,\n",
       " 42.00946746504998,\n",
       " 48.1943794563022,\n",
       " 38.08930658201871,\n",
       " 37.27153493370829,\n",
       " 35.73273129801604,\n",
       " 40.83959143979082,\n",
       " 42.84578410883718,\n",
       " 30.86754890295897,\n",
       " 41.25106347299559,\n",
       " 38.60749295475438,\n",
       " 41.59353702032431,\n",
       " 42.43825552216036,\n",
       " 43.31921287413374,\n",
       " 30.33977022164902,\n",
       " 40.320233154664564,\n",
       " 51.01496583858563,\n",
       " 49.402394269351916,\n",
       " 44.2206332125785,\n",
       " 35.59254797386377,\n",
       " 39.67286758068279,\n",
       " 42.031705666806914,\n",
       " 42.16913794473972,\n",
       " 35.06360435171653,\n",
       " 33.562051721166114,\n",
       " 38.95567734445321,\n",
       " 49.61521986341525,\n",
       " 35.406656586445294,\n",
       " 34.21185459395395,\n",
       " 38.18420267468134,\n",
       " 36.888217515709435,\n",
       " 40.23521629213764,\n",
       " 40.58717906893446,\n",
       " 39.08003544225628,\n",
       " 50.72883597554678,\n",
       " 58.022354830518566,\n",
       " 43.657421041279896,\n",
       " 41.17007147951008,\n",
       " 37.589085400055964,\n",
       " 32.260456317215144,\n",
       " 33.57731862781892,\n",
       " 39.20488183700483,\n",
       " 45.179289950284655,\n",
       " 39.091485777953814,\n",
       " 35.977403627054045,\n",
       " 40.60295782892711,\n",
       " 39.102031413431085,\n",
       " 36.66671310709882,\n",
       " 38.97939305139927,\n",
       " 47.779090187438285,\n",
       " 41.152647677443724,\n",
       " 37.66701028911844,\n",
       " 26.190659661993852,\n",
       " 39.975760552189506,\n",
       " 51.94552828994033,\n",
       " 38.14838830583072,\n",
       " 28.10318001906098,\n",
       " 46.71735635507447,\n",
       " 44.572410901247856,\n",
       " 35.85439626903436,\n",
       " 38.38475876092101,\n",
       " 24.744339482091377,\n",
       " 35.178903195401574,\n",
       " 33.4890800801258,\n",
       " 43.346736789651786,\n",
       " 38.05967305846841,\n",
       " 42.56755237881792,\n",
       " 43.81140688797848,\n",
       " 29.47613460722737,\n",
       " 43.083492700861974,\n",
       " 29.044144975179698,\n",
       " 45.37805159996389,\n",
       " 35.45084166574871,\n",
       " 38.96815608900005,\n",
       " 36.95188844942437,\n",
       " 41.108381824348456,\n",
       " 35.207462900834706,\n",
       " 39.01107009316034,\n",
       " 39.786641620786384,\n",
       " 49.19601964013241,\n",
       " 34.17595034177539,\n",
       " 46.54887950668839,\n",
       " 42.25036752509061,\n",
       " 49.46272488980197,\n",
       " 47.193264580582294,\n",
       " 50.69808118398975,\n",
       " 41.371862337852484,\n",
       " 46.879133445090616,\n",
       " 38.459051180803286,\n",
       " 37.235775909981,\n",
       " 41.71840557283447,\n",
       " 39.55138695086829,\n",
       " 46.75177889165489,\n",
       " 38.1053015408748,\n",
       " 39.17182013743404,\n",
       " 35.145171612330344,\n",
       " 35.40168574470666,\n",
       " 30.11110162334017,\n",
       " 42.25257920585271,\n",
       " 39.49908720354046,\n",
       " 27.32180182379447,\n",
       " 42.50625167833037,\n",
       " 42.209073188974244,\n",
       " 37.55180573665946,\n",
       " 43.46226292152508,\n",
       " 45.31639294247632,\n",
       " 47.26220070173609,\n",
       " 38.66016917836496,\n",
       " 46.122130445840114,\n",
       " 34.383618732002105,\n",
       " 35.31617250250443,\n",
       " 39.95030324414271,\n",
       " 45.238577254578026,\n",
       " 44.42813390648355,\n",
       " 36.782838046217755,\n",
       " 38.507769409602005,\n",
       " 44.26816744743802,\n",
       " 35.09881072740963,\n",
       " 29.237331916325946,\n",
       " 45.89733635834741,\n",
       " 36.020886722686456,\n",
       " 33.67224242902946,\n",
       " 42.184524364099175,\n",
       " 30.30898438631424,\n",
       " 35.82866416270352,\n",
       " 49.019349842314476,\n",
       " 37.759864239734156,\n",
       " 39.75984498536601,\n",
       " 41.774923783297695,\n",
       " 48.61426909592095,\n",
       " 34.89869663935135,\n",
       " 38.07262459442622,\n",
       " 42.7953102720101,\n",
       " 37.39042778872816,\n",
       " 40.25315120445516,\n",
       " 40.386385112200585,\n",
       " 39.012047160109844,\n",
       " 38.08652136348113,\n",
       " 50.74977352191716,\n",
       " 34.62222945433078,\n",
       " 42.13490192811897,\n",
       " 44.71203893139525,\n",
       " 31.304803441920292,\n",
       " 42.460456825639696,\n",
       " 47.91169755249422,\n",
       " 46.411190315202916,\n",
       " 38.691069279015224,\n",
       " 31.313195753079263,\n",
       " 44.33816033344963,\n",
       " 37.89810605352026,\n",
       " 37.59911971869461,\n",
       " 44.06141824223966,\n",
       " 36.51895342529472,\n",
       " 35.003792213228806,\n",
       " 45.832297822255,\n",
       " 36.66120434797132,\n",
       " 37.46188464545059,\n",
       " 33.410712801510115,\n",
       " 34.24124017683663,\n",
       " 41.569564859928676,\n",
       " 37.670589254488,\n",
       " 27.29544338684409,\n",
       " 46.187860942477506,\n",
       " 43.43684629319414,\n",
       " 29.87046183780378,\n",
       " 27.118496713330547,\n",
       " 39.45119673549059,\n",
       " 39.29760469415341,\n",
       " 52.37277557896648,\n",
       " 35.29099155123372,\n",
       " 39.32264837418625,\n",
       " 33.66569364404013,\n",
       " 30.23762958605091,\n",
       " 31.726109450566838,\n",
       " 41.4155571646776,\n",
       " 39.91727095852174,\n",
       " 39.71542480196542,\n",
       " 39.66300576849339,\n",
       " 36.10465170627312,\n",
       " 34.18693365326958,\n",
       " 38.69275596818435,\n",
       " 40.678320983847115,\n",
       " 47.12286846192882,\n",
       " 37.53407926297599,\n",
       " 52.09572520409364,\n",
       " 39.96884730273871,\n",
       " 30.797882424865538,\n",
       " 49.933888680798525,\n",
       " 39.036125653077775,\n",
       " 48.54765996955558,\n",
       " 42.21936321613759,\n",
       " 36.7077679377069,\n",
       " 44.9138152069278,\n",
       " 37.45639795365148,\n",
       " 35.07343083245556,\n",
       " 31.555976117691095,\n",
       " 33.88230943479287,\n",
       " 35.70846804230399,\n",
       " 34.51595596367631,\n",
       " 49.86421542375264,\n",
       " 41.48460662492867,\n",
       " 40.51793502414107,\n",
       " 37.06564641510464,\n",
       " 43.91276074423577,\n",
       " 43.93460559053612,\n",
       " 33.285120146246946,\n",
       " 41.623607722875704,\n",
       " 38.76159019588643,\n",
       " 34.041387663545414,\n",
       " 33.71553155607264,\n",
       " 32.34744349432971,\n",
       " 31.206901516994048,\n",
       " 33.383442921009966,\n",
       " 42.48402639089694,\n",
       " 49.53116524489091,\n",
       " 37.537030311325665,\n",
       " 38.58988318635488,\n",
       " 49.39431742131207,\n",
       " 39.27257686836572,\n",
       " 40.32032995807412,\n",
       " 42.85271191632705,\n",
       " 42.39766986244321,\n",
       " 44.844543075594046,\n",
       " 43.054078225718726,\n",
       " 44.102089316917514,\n",
       " 43.20864269960407,\n",
       " 44.216488015294466,\n",
       " 26.75069385894168,\n",
       " 35.30291652518567,\n",
       " 35.60728534155188,\n",
       " 37.703007749488904,\n",
       " 27.452936857826188,\n",
       " 41.601571574430295,\n",
       " 42.39945551578715,\n",
       " 37.25321568654302,\n",
       " 41.835421073376935,\n",
       " 34.45546981250848,\n",
       " 36.06824519925315,\n",
       " 41.2353356344704,\n",
       " 34.85641301177117,\n",
       " 37.89558703336875,\n",
       " 42.072600124838296,\n",
       " 40.23813690072148,\n",
       " 48.94787794303153,\n",
       " 43.873413573666696,\n",
       " 43.62901465572812,\n",
       " 41.837205885512795,\n",
       " 30.79833877615348,\n",
       " 31.831159342497312,\n",
       " 40.72219739714696,\n",
       " 32.889359306818235,\n",
       " 42.85344048326668,\n",
       " 35.08240026964412,\n",
       " 32.03556278363849,\n",
       " 45.59362850849813,\n",
       " 46.16337242839963,\n",
       " 38.49936414732135,\n",
       " 47.352471246970566,\n",
       " 32.94896633478024,\n",
       " 36.907751283470084,\n",
       " 35.373843963337414,\n",
       " 47.33916694745147,\n",
       " 42.50544356724696,\n",
       " 41.20181115264268,\n",
       " 39.21705204388763,\n",
       " 36.64351945548267,\n",
       " 43.804060587231945,\n",
       " 38.97186871641638,\n",
       " 40.77355611229742,\n",
       " 35.27531981356704,\n",
       " 27.915958937717857,\n",
       " 46.32764170693971,\n",
       " 37.546456715174244,\n",
       " 25.755856739475963,\n",
       " 32.90985581328404,\n",
       " 48.0885297747417,\n",
       " 44.84811409988064,\n",
       " 28.513419144372087,\n",
       " 32.27456665396768,\n",
       " 44.27519823170466,\n",
       " 42.362876939948045,\n",
       " 34.47086476873366,\n",
       " 34.67480550763299,\n",
       " 49.394240998660756,\n",
       " 27.023079064484175,\n",
       " 37.36894396634743,\n",
       " 48.702289373924195,\n",
       " 42.416420325956494,\n",
       " 39.56043266362893,\n",
       " 38.4316788535145,\n",
       " 36.89081780436166,\n",
       " 45.832977188166716,\n",
       " 43.488345383029475,\n",
       " 39.04503046042911,\n",
       " 31.619501806111874,\n",
       " 41.3395139037037,\n",
       " 42.64131682675147,\n",
       " 35.63878783250805,\n",
       " 39.76810548218005,\n",
       " 34.84923070830375,\n",
       " 40.389718904462114,\n",
       " 38.24739692595439,\n",
       " 45.93413078391934,\n",
       " 38.05378350374617,\n",
       " 34.94302341829627,\n",
       " 37.38313211524756,\n",
       " 39.108478196944745,\n",
       " 38.70500134370019,\n",
       " 37.46426392467292,\n",
       " 30.93776838774944,\n",
       " 23.73675315711983,\n",
       " 36.0312289772679,\n",
       " 34.549452095198106,\n",
       " 28.522200483963836,\n",
       " 46.487798999717384,\n",
       " 27.478764973031968,\n",
       " 35.60347267626476,\n",
       " 43.22060964322648,\n",
       " 39.951143889104024,\n",
       " 44.09780289203727,\n",
       " 33.54945558959621,\n",
       " 42.48617513284617,\n",
       " 40.32117666879514,\n",
       " 35.561834314148726,\n",
       " 35.867517607099636,\n",
       " 34.715906194356066,\n",
       " 25.960967842629465,\n",
       " 33.86526234784168,\n",
       " 36.84610120920367,\n",
       " 32.358455207370994,\n",
       " 43.04280327616031,\n",
       " 36.67407527659747,\n",
       " 35.79031707009108,\n",
       " 25.281223715277527,\n",
       " 55.67498957072055,\n",
       " 48.36145824563569,\n",
       " 34.24697071443391,\n",
       " 30.223511578575078,\n",
       " 41.16070658463529,\n",
       " 33.35727639291371,\n",
       " 32.63743912803231,\n",
       " 44.022768510441374,\n",
       " 30.52322954798555,\n",
       " 48.68747923245347,\n",
       " 38.02703073958095,\n",
       " 46.36476485770886,\n",
       " 39.207585564750794,\n",
       " 41.597860349584586,\n",
       " 33.85093470301177,\n",
       " 38.83035080041388,\n",
       " 39.35275210912558,\n",
       " 39.60780321436789,\n",
       " 36.373316873089976,\n",
       " 33.67976304982987,\n",
       " 43.84389454466445,\n",
       " 43.02754233165474,\n",
       " 35.800480214713225,\n",
       " 40.489099062917035,\n",
       " 35.832594344031136,\n",
       " 24.039508271835228,\n",
       " 45.07446240065919,\n",
       " 39.25948013989449,\n",
       " 40.87974572197395,\n",
       " 36.70078243995963,\n",
       " 54.48866410082601,\n",
       " 27.880721779300178,\n",
       " 34.89761750995535,\n",
       " 44.07954650719546,\n",
       " 39.072968274319365,\n",
       " 30.773683110498098,\n",
       " 39.3815723930011,\n",
       " 43.16879430523447,\n",
       " 49.24908544103057,\n",
       " 36.724184971170175,\n",
       " 33.73506392818368,\n",
       " 37.436020159210685,\n",
       " 40.02934759708989,\n",
       " 40.7090720256308,\n",
       " 39.28285039158037,\n",
       " 30.54210701716205,\n",
       " 42.07640972808569,\n",
       " 41.4889959332463,\n",
       " 31.327021587170247,\n",
       " 37.372724509633294,\n",
       " 37.175043848561245,\n",
       " 35.33337539273217,\n",
       " 39.92291268325714,\n",
       " 39.341622671832525,\n",
       " 32.80561090451057,\n",
       " 34.3477498496144,\n",
       " 45.98466468688612,\n",
       " 36.88929768647249,\n",
       " 42.802354315938246,\n",
       " 44.41263803003238,\n",
       " 39.746717982417394,\n",
       " 28.635029250623553,\n",
       " 40.59861368499003,\n",
       " 26.677643391242533,\n",
       " 33.36130387186753,\n",
       " 46.19202495840991,\n",
       " 39.3659078981299,\n",
       " 35.861368943205406,\n",
       " 42.64854984905066,\n",
       " 34.417773281858196,\n",
       " 41.5227480864876,\n",
       " 28.78234964719934,\n",
       " 32.112826685548,\n",
       " 43.33467372780199,\n",
       " 43.879852578043824,\n",
       " 41.13331890962534,\n",
       " 39.74536204570807,\n",
       " 40.47003039197595,\n",
       " 28.693773429280327,\n",
       " 42.69989429561782,\n",
       " 30.487993467401754,\n",
       " 40.21964968718565,\n",
       " 39.54768133203662,\n",
       " 26.27338220248215,\n",
       " 41.57467893160287,\n",
       " 40.72678493767428,\n",
       " 29.125512088808943,\n",
       " 31.114227939064005,\n",
       " 33.8823325596363,\n",
       " 24.34340873036601,\n",
       " 32.37669061614802,\n",
       " 28.195887288117614,\n",
       " 31.686828793715033,\n",
       " 45.285821404407386,\n",
       " 38.93336180854579,\n",
       " 43.93683949560582,\n",
       " 33.499416507830595,\n",
       " 31.915097248745166,\n",
       " 49.504839090085014,\n",
       " 38.150324323736264,\n",
       " 42.23498952630873,\n",
       " 43.212783969809344,\n",
       " 39.67864721743704,\n",
       " 36.76718977892243,\n",
       " 35.94817020956616,\n",
       " 30.339862806030645,\n",
       " 32.9812098577934,\n",
       " 31.753167187130817,\n",
       " 43.17586151410118,\n",
       " 40.921736135755374,\n",
       " 39.12047370501513,\n",
       " 38.3326736441573,\n",
       " 40.381374723078,\n",
       " 36.81065594729173,\n",
       " 38.85114454093421,\n",
       " 40.80021721800361,\n",
       " 28.87444202183833,\n",
       " 27.41155661300195,\n",
       " 38.04139771442665,\n",
       " 40.87791629026343,\n",
       " 34.114888438234985,\n",
       " 32.366723269713816,\n",
       " 39.07609884146137,\n",
       " 32.076570644761915,\n",
       " 36.300513160304966,\n",
       " 31.94967840868984,\n",
       " 37.69451518626496,\n",
       " 32.18815589589658,\n",
       " 35.28081748948493,\n",
       " 37.18464751825448,\n",
       " 44.25561114893088,\n",
       " 47.93588477488808,\n",
       " 40.43773988998151,\n",
       " 44.10238734191938,\n",
       " 38.52663509683119,\n",
       " 38.658755585167796,\n",
       " 27.134784070829586,\n",
       " 37.37387852391484,\n",
       " 41.207483723439815,\n",
       " 38.30409417804041,\n",
       " 47.21812211503513,\n",
       " 41.22397046375418,\n",
       " 36.19607062964023,\n",
       " 39.41897645490839,\n",
       " 41.29212734651186,\n",
       " 45.05002830345486,\n",
       " 35.395349597948105,\n",
       " 33.94148640230202,\n",
       " 41.93620927256093,\n",
       " 35.84111591139255,\n",
       " 44.200989334381354,\n",
       " 35.8466302412033,\n",
       " 44.15043771989092,\n",
       " 39.98883654531543,\n",
       " 37.7025821276329,\n",
       " 49.84236114497306,\n",
       " 42.72406279411742,\n",
       " 42.59747690446556,\n",
       " 39.94038983776007,\n",
       " 31.679953914451794,\n",
       " 30.89833684897402,\n",
       " 40.98946111027486,\n",
       " 36.73036275550467,\n",
       " 38.09844016656816,\n",
       " 31.74857991379621,\n",
       " 37.34552623245846,\n",
       " 36.30291903701531,\n",
       " 41.69772510315913,\n",
       " 24.835078161882837,\n",
       " 30.90194529532037,\n",
       " 28.64577797790319,\n",
       " 55.10970426601388,\n",
       " 34.201867559047294,\n",
       " 50.455032570996806,\n",
       " 39.199479163761005,\n",
       " 37.71138170553451,\n",
       " 36.27085214235019,\n",
       " 31.712578608017264,\n",
       " 43.64112669650923,\n",
       " 36.946859412240144,\n",
       " 43.73136866985623,\n",
       " 40.964034831120145,\n",
       " 26.70778769071702,\n",
       " 36.0361886104091,\n",
       " 40.22915957176856,\n",
       " 41.286933312770444,\n",
       " 35.99864471172735,\n",
       " 24.550955493185917,\n",
       " 38.76990580421646,\n",
       " 36.90133289730827,\n",
       " 37.367742621007025,\n",
       " 34.26430987385528,\n",
       " 34.274393453332756,\n",
       " 33.54790576896171,\n",
       " 39.261641478083845,\n",
       " 31.727331889004596,\n",
       " 37.25713391669838,\n",
       " 40.776979377246235,\n",
       " 34.86816100966267,\n",
       " 28.868507494251595,\n",
       " 37.71481124532888,\n",
       " 30.581541938143594,\n",
       " 36.874457764303656,\n",
       " 39.67898125255122,\n",
       " 37.52559398558841,\n",
       " 35.34252254422754,\n",
       " 34.100552615375854,\n",
       " 39.9133603054428,\n",
       " 39.13217929678856,\n",
       " 40.886910870556314,\n",
       " 42.136297478787824,\n",
       " 43.65183333103497,\n",
       " 35.55442791429219,\n",
       " 36.84728858650688,\n",
       " 29.48811761608348,\n",
       " 34.19143430263201,\n",
       " 35.34060332481749,\n",
       " 44.911594385555475,\n",
       " 38.21317485153334,\n",
       " 32.681575811467795,\n",
       " 47.910166106411936,\n",
       " 39.910500011849344,\n",
       " 42.853366551076554,\n",
       " 34.464912272884796,\n",
       " 42.539482809009044,\n",
       " 35.69915048928961,\n",
       " 37.01847699179994,\n",
       " 38.650721073909125,\n",
       " 36.376951627328566,\n",
       " 38.331494499703076,\n",
       " 38.34553778764856,\n",
       " 43.862519844264256,\n",
       " 26.43080464690353,\n",
       " 41.28660491233689,\n",
       " 35.487119354910874,\n",
       " 47.56974937240052,\n",
       " 28.154181336588557,\n",
       " 35.38556634653747,\n",
       " 37.13642272871465,\n",
       " 30.819844977735407,\n",
       " 46.30709820500119,\n",
       " 48.85330425435489,\n",
       " 39.04859373183226,\n",
       " 29.951280568392246,\n",
       " 30.221587237904373,\n",
       " 40.04048242587992,\n",
       " 33.71266575244387,\n",
       " 37.122321445440875,\n",
       " 36.38238945180909,\n",
       " 40.17884539462962,\n",
       " 48.966071230566925,\n",
       " 39.898112109743735,\n",
       " 33.41556678017331,\n",
       " 34.4195026060288,\n",
       " 37.965713552890506,\n",
       " 31.01608821044932,\n",
       " 39.360240853732805,\n",
       " 41.248073780312374,\n",
       " 32.3447984108237,\n",
       " 37.6705112984142,\n",
       " 27.30774745683824,\n",
       " 32.74451300648663,\n",
       " 51.8309075294611,\n",
       " 37.155225352184424,\n",
       " 42.42769727038757,\n",
       " 34.43778892349019,\n",
       " 30.771377519762762,\n",
       " 25.952900867598792,\n",
       " 42.26550242205637,\n",
       " 31.38489863357437,\n",
       " 34.092101503267806,\n",
       " 34.693153885199116,\n",
       " 36.152461692869295,\n",
       " 35.01068332311509,\n",
       " 42.38795588751962,\n",
       " 27.560668832903712,\n",
       " 53.117538699070224,\n",
       " 36.0514305199937,\n",
       " 36.11608923407858,\n",
       " 35.210852740015476,\n",
       " 32.30938127965584,\n",
       " 35.87701097265244,\n",
       " 39.36669603328043,\n",
       " 41.93578301178464,\n",
       " 39.93332882019274,\n",
       " 34.043210578703054,\n",
       " 29.486076122208992,\n",
       " 40.98726784984791,\n",
       " 36.685339287708835,\n",
       " 42.64275763797592,\n",
       " 25.356562816261924,\n",
       " 23.884817345018984,\n",
       " 38.96398465546058,\n",
       " 42.70480582205755,\n",
       " 50.3122190095868,\n",
       " 34.12280191542545,\n",
       " 24.893338160136558,\n",
       " 32.38877411936644,\n",
       " 33.22244186991152,\n",
       " 26.834162201948118,\n",
       " 30.878646645742627,\n",
       " 37.460105778505365,\n",
       " 33.16167412139331,\n",
       " 36.96092092301696,\n",
       " 43.84380564527666,\n",
       " 37.42797645906226,\n",
       " 37.38126090539654,\n",
       " 34.92398664716963,\n",
       " 32.637323558078435,\n",
       " 38.11796864470874,\n",
       " 43.354452162014624,\n",
       " 39.60255632020777,\n",
       " 34.2745704337939,\n",
       " 34.1335952260941,\n",
       " 36.68743330372066,\n",
       " 46.41819125977179,\n",
       " 40.86133967310378,\n",
       " 39.22721104766803,\n",
       " 34.26953417729209,\n",
       " 41.033783035224964,\n",
       " 42.33119872734138,\n",
       " 45.68009759413479,\n",
       " 43.32270986954583,\n",
       " 29.98992258217453,\n",
       " 47.60144490905856,\n",
       " 28.768383519772605,\n",
       " 36.550902444037135,\n",
       " 37.27756211071069,\n",
       " 36.65950449076333,\n",
       " 39.50120265789834,\n",
       " 31.14661070211516,\n",
       " 39.619098725178034,\n",
       " 39.867885560285806,\n",
       " 41.31874034894953,\n",
       " 42.13564364330859,\n",
       " 42.48292431244511,\n",
       " 38.86320294626429,\n",
       " 36.762583134626624,\n",
       " 41.49515029712868,\n",
       " 35.342089059944946,\n",
       " 37.127625420760666,\n",
       " 27.75270040258256,\n",
       " 37.997534216003366,\n",
       " 37.19696318937057,\n",
       " 34.610768794033845,\n",
       " 40.415745009897286,\n",
       " 31.1968938161114,\n",
       " 44.88013200864585,\n",
       " 46.80169235460387,\n",
       " 29.704345753280307,\n",
       " 34.37001535099968,\n",
       " 38.57093522956795,\n",
       " 34.55986839627978,\n",
       " 44.328459090560756,\n",
       " 34.45883926106048,\n",
       " 34.71006785966886,\n",
       " 30.702314783007346,\n",
       " 43.139947821858954,\n",
       " 44.03863159911289,\n",
       " 26.70554347292682,\n",
       " 31.959773460767043,\n",
       " 36.47345955486386,\n",
       " 40.310074832696536,\n",
       " 35.306051119805474,\n",
       " 30.89194201920776,\n",
       " 35.84708873297862,\n",
       " 42.95876615132869,\n",
       " 30.80801711987873,\n",
       " 45.41641460188539,\n",
       " 33.453432626275585,\n",
       " 38.33603019418457,\n",
       " 37.082287229622956,\n",
       " 43.38925603409149,\n",
       " 40.190061573259904,\n",
       " 28.383887974281606,\n",
       " 41.007827658927205,\n",
       " 34.32625334789495,\n",
       " 27.91014836529704,\n",
       " 42.21701931832048,\n",
       " 34.437482165001384,\n",
       " 38.429388311536414,\n",
       " 41.603276197674724,\n",
       " 31.427889991763767,\n",
       " 34.86038119325365,\n",
       " 40.52635883222231,\n",
       " 33.57797537729895,\n",
       " 36.488014893827966,\n",
       " 33.69098503981951,\n",
       " 32.39111536783886,\n",
       " 48.335176305926204,\n",
       " 38.669503866590745,\n",
       " 30.638169804493202,\n",
       " 35.43693704195566,\n",
       " 40.82922045946254,\n",
       " 37.24217758511392,\n",
       " 36.3011136182084,\n",
       " 33.96705584272547,\n",
       " 34.30116783928425,\n",
       " 41.31696195033565,\n",
       " 51.6769963938619,\n",
       " 32.35783870553379,\n",
       " 36.59180218649541,\n",
       " 24.712357283102236,\n",
       " 37.57361750880888,\n",
       " 28.002686203961787,\n",
       " 38.762211333904006,\n",
       " 38.6267583607669,\n",
       " 41.034418847277756,\n",
       " 34.32249125488416,\n",
       " 39.043336098565206,\n",
       " 23.74796113476969,\n",
       " 41.21902032774831,\n",
       " 43.94347542871301,\n",
       " 49.97158091086829,\n",
       " 33.84816969194059,\n",
       " 40.64753192857925,\n",
       " 39.54159084243658,\n",
       " 40.416131915121845,\n",
       " 27.30208702209797,\n",
       " 48.39524142455824,\n",
       " 37.44478628060339,\n",
       " 38.26428287359587,\n",
       " 34.5119075570623,\n",
       " 33.75605433360265,\n",
       " 32.98582399173081,\n",
       " 36.8360492256684,\n",
       " 37.522780611904054,\n",
       " 33.67723305435357,\n",
       " 35.132750109220794,\n",
       " 28.16258923854544,\n",
       " 39.214332880936944,\n",
       " 44.533042284953844,\n",
       " 44.32225968173463,\n",
       " 40.837000839719074,\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes.error_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
