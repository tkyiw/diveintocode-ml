{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/anaconda3/envs/tensorflow_p36\n",
      "\n",
      "  added / updated specs: \n",
      "    - tqdm\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.0.2u             |       h7b6447c_0         3.1 MB\n",
      "    ca-certificates-2020.1.1   |                0         132 KB\n",
      "    tqdm-4.46.1                |             py_0          60 KB\n",
      "    certifi-2020.6.20          |           py36_0         160 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    tqdm:            4.46.1-py_0      \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates: 2019.10.16-0      --> 2020.1.1-0       \n",
      "    certifi:         2019.9.11-py36_0  --> 2020.6.20-py36_0 \n",
      "    openssl:         1.0.2t-h7b6447c_1 --> 1.0.2u-h7b6447c_0\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.0.2u       | 3.1 MB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 132 KB    | ##################################### | 100% \n",
      "tqdm-4.46.1          | 60 KB     | ##################################### | 100% \n",
      "certifi-2020.6.20    | 160 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install tqdm -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:39.259864Z",
     "start_time": "2020-03-25T14:39:39.039884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /home/ubuntu/'input'/train.zip -d /home/ubuntu/'input'/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /home/ubuntu/'input'/test.zip -d /home/ubuntu/'input'/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "depth = pd.read_csv('./input/depths.csv')\n",
    "\n",
    "train_src = './input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:59.083122Z",
     "start_time": "2020-03-25T14:39:58.584544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7d7bd07ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    }
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.952868Z",
     "start_time": "2020-03-25T14:40:35.927679Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:43.034360Z",
     "start_time": "2020-03-25T14:40:35.954603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 1s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:46.197121Z",
     "start_time": "2020-03-25T14:40:46.188335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:54:51.684488Z",
     "start_time": "2020-03-25T14:54:51.673231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:55:00.601042Z",
     "start_time": "2020-03-25T14:54:53.772115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-17-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,903,873\n",
      "Trainable params: 42,852,737\n",
      "Non-trainable params: 51,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T17:37:03.773696Z",
     "start_time": "2020-03-25T14:58:43.483800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,970,161\n",
      "Trainable params: 48,915,857\n",
      "Non-trainable params: 54,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/15\n",
      "3196/3196 [==============================] - 323s 101ms/step - loss: 0.7124 - my_iou_metric: 0.3925 - val_loss: 0.7314 - val_my_iou_metric: 0.4287\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.42873, saving model to unet_resnet.h5\n",
      "Epoch 2/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.5758 - my_iou_metric: 0.5191 - val_loss: 0.7106 - val_my_iou_metric: 0.3810\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.42873\n",
      "Epoch 3/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.5004 - my_iou_metric: 0.5549 - val_loss: 1.2330 - val_my_iou_metric: 0.2660\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.42873\n",
      "Epoch 4/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.4787 - my_iou_metric: 0.5590 - val_loss: 0.4312 - val_my_iou_metric: 0.5999\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.42873 to 0.59988, saving model to unet_resnet.h5\n",
      "Epoch 5/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.4926 - my_iou_metric: 0.5819 - val_loss: 1.0008 - val_my_iou_metric: 0.4097\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.59988\n",
      "Epoch 6/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.4427 - my_iou_metric: 0.6062 - val_loss: 0.4792 - val_my_iou_metric: 0.6556\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.59988 to 0.65560, saving model to unet_resnet.h5\n",
      "Epoch 7/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.4051 - my_iou_metric: 0.6207 - val_loss: 0.4622 - val_my_iou_metric: 0.6378\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.65560\n",
      "Epoch 8/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3994 - my_iou_metric: 0.6327 - val_loss: 0.4025 - val_my_iou_metric: 0.6565\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.65560 to 0.65647, saving model to unet_resnet.h5\n",
      "Epoch 9/15\n",
      "3196/3196 [==============================] - 238s 75ms/step - loss: 0.3897 - my_iou_metric: 0.6379 - val_loss: 0.3895 - val_my_iou_metric: 0.6248\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.65647\n",
      "Epoch 10/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3773 - my_iou_metric: 0.6546 - val_loss: 0.4406 - val_my_iou_metric: 0.6502\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.65647\n",
      "Epoch 11/15\n",
      "3196/3196 [==============================] - 238s 75ms/step - loss: 0.3648 - my_iou_metric: 0.6498 - val_loss: 0.4380 - val_my_iou_metric: 0.6335\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.65647\n",
      "Epoch 12/15\n",
      "3196/3196 [==============================] - 238s 75ms/step - loss: 0.3624 - my_iou_metric: 0.6594 - val_loss: 0.3715 - val_my_iou_metric: 0.6900\n",
      "\n",
      "Epoch 00012: val_my_iou_metric improved from 0.65647 to 0.69005, saving model to unet_resnet.h5\n",
      "Epoch 13/15\n",
      "3196/3196 [==============================] - 238s 75ms/step - loss: 0.3331 - my_iou_metric: 0.6702 - val_loss: 0.4461 - val_my_iou_metric: 0.6343\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.69005\n",
      "Epoch 14/15\n",
      "3196/3196 [==============================] - 238s 75ms/step - loss: 0.3509 - my_iou_metric: 0.6710 - val_loss: 0.3871 - val_my_iou_metric: 0.6951\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.69005 to 0.69515, saving model to unet_resnet.h5\n",
      "Epoch 15/15\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3273 - my_iou_metric: 0.6804 - val_loss: 0.4719 - val_my_iou_metric: 0.6532\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.69515\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 15  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:47<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6889 at threshold: 0.840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.671727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.015566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.624751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.669838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.676244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.681095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.688930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.671727\n",
       "std     0.204939   0.015566\n",
       "min     0.200000   0.624751\n",
       "25%     0.370000   0.669838\n",
       "50%     0.540000   0.676244\n",
       "75%     0.710000   0.681095\n",
       "max     0.880000   0.688930"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c5e061080>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "\n",
    "\n",
    "\n",
    "### \n",
    "\n",
    "\n",
    "-   \n",
    "ResNet\n",
    "-   \n",
    "ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "    \n",
    "    # ImageNet weights\n",
    "    model_depth = unet_resnet(input_size, decoder_block_bottleneck,\n",
    "                              weights='imagenet',\n",
    "                              loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "                              use_lovash=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "ResNetVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 1s 0us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = VGG19(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_conv4\n",
      "11 block3_pool\n",
      "12 block4_conv1\n",
      "13 block4_conv2\n",
      "14 block4_conv3\n",
      "15 block4_conv4\n",
      "16 block4_pool\n",
      "17 block5_conv1\n",
      "18 block5_conv2\n",
      "19 block5_conv3\n",
      "20 block5_conv4\n",
      "21 block5_pool\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19\n",
    "def unet_vgg(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG19(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block2_conv2').output \n",
    "    encoder2 = base_model.get_layer('block3_conv2').output \n",
    "    encoder3 = base_model.get_layer('block4_conv3').output \n",
    "    encoder4 = base_model.get_layer('block5_conv3').output \n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # model20\n",
    "    for layer in model.layers[:21]:\n",
    "        layer.trainable = False\n",
    " \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "ResNetVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 34,226,801\n",
      "Trainable params: 14,197,137\n",
      "Non-trainable params: 20,029,664\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_depth.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/15\n",
      "3196/3196 [==============================] - 189s 59ms/step - loss: 0.7768 - my_iou_metric: 0.2015 - val_loss: 1.8271 - val_my_iou_metric: 0.3168\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.31679, saving model to unet_vgg.h5\n",
      "Epoch 2/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.5947 - my_iou_metric: 0.3058 - val_loss: 1.2489 - val_my_iou_metric: 0.3904\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.31679 to 0.39042, saving model to unet_vgg.h5\n",
      "Epoch 3/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.5375 - my_iou_metric: 0.3977 - val_loss: 0.6579 - val_my_iou_metric: 0.5468\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.39042 to 0.54677, saving model to unet_vgg.h5\n",
      "Epoch 4/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.5004 - my_iou_metric: 0.4468 - val_loss: 0.6549 - val_my_iou_metric: 0.5516\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.54677 to 0.55162, saving model to unet_vgg.h5\n",
      "Epoch 5/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4734 - my_iou_metric: 0.4753 - val_loss: 0.4932 - val_my_iou_metric: 0.5493\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.55162\n",
      "Epoch 6/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4801 - my_iou_metric: 0.4834 - val_loss: 0.7931 - val_my_iou_metric: 0.5219\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.55162\n",
      "Epoch 7/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4439 - my_iou_metric: 0.5203 - val_loss: 0.6513 - val_my_iou_metric: 0.5595\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.55162 to 0.55945, saving model to unet_vgg.h5\n",
      "Epoch 8/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4235 - my_iou_metric: 0.5479 - val_loss: 0.5392 - val_my_iou_metric: 0.6030\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.55945 to 0.60299, saving model to unet_vgg.h5\n",
      "Epoch 9/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4427 - my_iou_metric: 0.5262 - val_loss: 0.4753 - val_my_iou_metric: 0.6180\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.60299 to 0.61803, saving model to unet_vgg.h5\n",
      "Epoch 10/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.4047 - my_iou_metric: 0.5579 - val_loss: 0.6108 - val_my_iou_metric: 0.4525\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.61803\n",
      "Epoch 11/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.3826 - my_iou_metric: 0.5658 - val_loss: 0.5362 - val_my_iou_metric: 0.5276\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.61803\n",
      "Epoch 12/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.3603 - my_iou_metric: 0.5839 - val_loss: 0.5710 - val_my_iou_metric: 0.6103\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.61803\n",
      "Epoch 13/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.3447 - my_iou_metric: 0.5973 - val_loss: 0.4229 - val_my_iou_metric: 0.5981\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.61803\n",
      "Epoch 14/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.3298 - my_iou_metric: 0.6053 - val_loss: 0.4332 - val_my_iou_metric: 0.5888\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.61803\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.2746 - my_iou_metric: 0.6356 - val_loss: 0.3999 - val_my_iou_metric: 0.6500\n",
      "\n",
      "Epoch 00015: val_my_iou_metric improved from 0.61803 to 0.65000, saving model to unet_vgg.h5\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 15  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_vgg = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred_vgg = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds_vgg)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:46<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred_vgg > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6604 at threshold: 0.540\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.652520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.007139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.631219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.649440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.655100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.657898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.660448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.652520\n",
       "std     0.204939   0.007139\n",
       "min     0.200000   0.631219\n",
       "25%     0.370000   0.649440\n",
       "50%     0.540000   0.655100\n",
       "75%     0.710000   0.657898\n",
       "max     0.880000   0.660448"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d48425e48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 pool1_pad\n",
      "6 max_pooling2d_1\n",
      "7 res2a_branch2a\n",
      "8 bn2a_branch2a\n",
      "9 activation_2\n",
      "10 res2a_branch2b\n",
      "11 bn2a_branch2b\n",
      "12 activation_3\n",
      "13 res2a_branch2c\n",
      "14 res2a_branch1\n",
      "15 bn2a_branch2c\n",
      "16 bn2a_branch1\n",
      "17 add_1\n",
      "18 activation_4\n",
      "19 res2b_branch2a\n",
      "20 bn2b_branch2a\n",
      "21 activation_5\n",
      "22 res2b_branch2b\n",
      "23 bn2b_branch2b\n",
      "24 activation_6\n",
      "25 res2b_branch2c\n",
      "26 bn2b_branch2c\n",
      "27 add_2\n",
      "28 activation_7\n",
      "29 res2c_branch2a\n",
      "30 bn2c_branch2a\n",
      "31 activation_8\n",
      "32 res2c_branch2b\n",
      "33 bn2c_branch2b\n",
      "34 activation_9\n",
      "35 res2c_branch2c\n",
      "36 bn2c_branch2c\n",
      "37 add_3\n",
      "38 activation_10\n",
      "39 res3a_branch2a\n",
      "40 bn3a_branch2a\n",
      "41 activation_11\n",
      "42 res3a_branch2b\n",
      "43 bn3a_branch2b\n",
      "44 activation_12\n",
      "45 res3a_branch2c\n",
      "46 res3a_branch1\n",
      "47 bn3a_branch2c\n",
      "48 bn3a_branch1\n",
      "49 add_4\n",
      "50 activation_13\n",
      "51 res3b_branch2a\n",
      "52 bn3b_branch2a\n",
      "53 activation_14\n",
      "54 res3b_branch2b\n",
      "55 bn3b_branch2b\n",
      "56 activation_15\n",
      "57 res3b_branch2c\n",
      "58 bn3b_branch2c\n",
      "59 add_5\n",
      "60 activation_16\n",
      "61 res3c_branch2a\n",
      "62 bn3c_branch2a\n",
      "63 activation_17\n",
      "64 res3c_branch2b\n",
      "65 bn3c_branch2b\n",
      "66 activation_18\n",
      "67 res3c_branch2c\n",
      "68 bn3c_branch2c\n",
      "69 add_6\n",
      "70 activation_19\n",
      "71 res3d_branch2a\n",
      "72 bn3d_branch2a\n",
      "73 activation_20\n",
      "74 res3d_branch2b\n",
      "75 bn3d_branch2b\n",
      "76 activation_21\n",
      "77 res3d_branch2c\n",
      "78 bn3d_branch2c\n",
      "79 add_7\n",
      "80 activation_22\n",
      "81 res4a_branch2a\n",
      "82 bn4a_branch2a\n",
      "83 activation_23\n",
      "84 res4a_branch2b\n",
      "85 bn4a_branch2b\n",
      "86 activation_24\n",
      "87 res4a_branch2c\n",
      "88 res4a_branch1\n",
      "89 bn4a_branch2c\n",
      "90 bn4a_branch1\n",
      "91 add_8\n",
      "92 activation_25\n",
      "93 res4b_branch2a\n",
      "94 bn4b_branch2a\n",
      "95 activation_26\n",
      "96 res4b_branch2b\n",
      "97 bn4b_branch2b\n",
      "98 activation_27\n",
      "99 res4b_branch2c\n",
      "100 bn4b_branch2c\n",
      "101 add_9\n",
      "102 activation_28\n",
      "103 res4c_branch2a\n",
      "104 bn4c_branch2a\n",
      "105 activation_29\n",
      "106 res4c_branch2b\n",
      "107 bn4c_branch2b\n",
      "108 activation_30\n",
      "109 res4c_branch2c\n",
      "110 bn4c_branch2c\n",
      "111 add_10\n",
      "112 activation_31\n",
      "113 res4d_branch2a\n",
      "114 bn4d_branch2a\n",
      "115 activation_32\n",
      "116 res4d_branch2b\n",
      "117 bn4d_branch2b\n",
      "118 activation_33\n",
      "119 res4d_branch2c\n",
      "120 bn4d_branch2c\n",
      "121 add_11\n",
      "122 activation_34\n",
      "123 res4e_branch2a\n",
      "124 bn4e_branch2a\n",
      "125 activation_35\n",
      "126 res4e_branch2b\n",
      "127 bn4e_branch2b\n",
      "128 activation_36\n",
      "129 res4e_branch2c\n",
      "130 bn4e_branch2c\n",
      "131 add_12\n",
      "132 activation_37\n",
      "133 res4f_branch2a\n",
      "134 bn4f_branch2a\n",
      "135 activation_38\n",
      "136 res4f_branch2b\n",
      "137 bn4f_branch2b\n",
      "138 activation_39\n",
      "139 res4f_branch2c\n",
      "140 bn4f_branch2c\n",
      "141 add_13\n",
      "142 activation_40\n",
      "143 res5a_branch2a\n",
      "144 bn5a_branch2a\n",
      "145 activation_41\n",
      "146 res5a_branch2b\n",
      "147 bn5a_branch2b\n",
      "148 activation_42\n",
      "149 res5a_branch2c\n",
      "150 res5a_branch1\n",
      "151 bn5a_branch2c\n",
      "152 bn5a_branch1\n",
      "153 add_14\n",
      "154 activation_43\n",
      "155 res5b_branch2a\n",
      "156 bn5b_branch2a\n",
      "157 activation_44\n",
      "158 res5b_branch2b\n",
      "159 bn5b_branch2b\n",
      "160 activation_45\n",
      "161 res5b_branch2c\n",
      "162 bn5b_branch2c\n",
      "163 add_15\n",
      "164 activation_46\n",
      "165 res5c_branch2a\n",
      "166 bn5c_branch2a\n",
      "167 activation_47\n",
      "168 res5c_branch2b\n",
      "169 bn5c_branch2b\n",
      "170 activation_48\n",
      "171 res5c_branch2c\n",
      "172 bn5c_branch2c\n",
      "173 add_16\n",
      "174 activation_49\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # model171\n",
    "    for layer in model.layers[:172]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,970,161\n",
      "Trainable params: 25,385,361\n",
      "Non-trainable params: 23,584,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/15\n",
      "3196/3196 [==============================] - 168s 53ms/step - loss: 0.6871 - my_iou_metric: 0.3625 - val_loss: 7.6116 - val_my_iou_metric: 0.1325\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.13246, saving model to unet_resnet.h5\n",
      "Epoch 2/15\n",
      "3196/3196 [==============================] - 155s 49ms/step - loss: 0.5275 - my_iou_metric: 0.4715 - val_loss: 1.6262 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.13246\n",
      "Epoch 3/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.4652 - my_iou_metric: 0.5089 - val_loss: 2.1919 - val_my_iou_metric: 0.3881\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.13246 to 0.38806, saving model to unet_resnet.h5\n",
      "Epoch 4/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.4373 - my_iou_metric: 0.5321 - val_loss: 1.7964 - val_my_iou_metric: 0.1206\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.38806\n",
      "Epoch 5/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.4018 - my_iou_metric: 0.5420 - val_loss: 2.0423 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.38806 to 0.38930, saving model to unet_resnet.h5\n",
      "Epoch 6/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.3857 - my_iou_metric: 0.5727 - val_loss: 2.7414 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 7/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.3485 - my_iou_metric: 0.6067 - val_loss: 2.1948 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 8/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.3478 - my_iou_metric: 0.6125 - val_loss: 1.8623 - val_my_iou_metric: 4.9751e-04\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 9/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.3244 - my_iou_metric: 0.6218 - val_loss: 1.6266 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 10/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.3070 - my_iou_metric: 0.6237 - val_loss: 2.5140 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.38930\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.2612 - my_iou_metric: 0.6686 - val_loss: 2.4349 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 12/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.2403 - my_iou_metric: 0.6835 - val_loss: 2.5229 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 13/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.2231 - my_iou_metric: 0.6810 - val_loss: 2.0869 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 14/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.2208 - my_iou_metric: 0.6920 - val_loss: 2.4964 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 15/15\n",
      "3196/3196 [==============================] - 156s 49ms/step - loss: 0.2027 - my_iou_metric: 0.6953 - val_loss: 3.0008 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.38930\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "epochs = 15  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_res = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred_res = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds_res)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:47<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred_res > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5218 at threshold: 0.340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.514684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.022169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.409701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.521766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.521766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.521766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.521766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.514684\n",
       "std     0.204939   0.022169\n",
       "min     0.200000   0.409701\n",
       "25%     0.370000   0.521766\n",
       "50%     0.540000   0.521766\n",
       "75%     0.710000   0.521766\n",
       "max     0.880000   0.521766"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c3a32cc88>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmUnXd95/nPT6XNlkrypsW2jCSIAzaGsMiGLCyd7iQkISY5JGncyQSTgLO5k5MmdEgnIQS6e5qkTzI9EyYzdIZAQ8DQnCxOcEJnmDAMYEOViVksYTCmbMtWSbIkq0q2q7TUb/6oK1EWcumWannu8nqd4+O6t55b9ZWuS3rz8Ht+T6m1BgAAOLNlTQ8AAACdTDADAMAsBDMAAMxCMAMAwCwEMwAAzEIwAwDALAQzAADMQjADAMAsBDMAAMxCMAMAwCyWNz3A6S655JK6bdu2pscAAKDH3XnnnY/UWjec7biOC+Zt27ZleHi46TEAAOhxpZT72znOkgwAAJiFYAYAgFkIZgAAmEXHrWE+k2PHjmX37t2ZmJhoepR5W716dbZs2ZIVK1Y0PQoAAG3oimDevXt3BgcHs23btpRSmh7nnNVac+DAgezevTvbt29vehwAANrQFUsyJiYmcvHFF3d1LCdJKSUXX3xxT5wpBwDoF10RzEm6PpZP6pVfBwBAv+iaYG7ad33XdzU9AgAADRDMbfrMZz7T9AgAADRAMLdp7dq1SaYv3HvTm96Ua665Js95znPyoQ99KEnyiU98Iq985StPHX/zzTfnPe95TxOjAgCwgLpil4yZfu9v7s7Oh8cW9Gtefdm6/O6PPLutY//iL/4id911V77whS/kkUceybXXXpuXvvSlCzoPAACdwxnmOfrUpz6VG264IQMDA9m0aVNe9rKXZWhoqOmxAABYJF13hrndM8FLbfny5Zmamjr12NZxAAC9wRnmOXrJS16SD33oQzlx4kT279+fT37yk7nuuuuydevW7Ny5M5OTk3n00Ufz8Y9/vOlRAQBYAF13hrlpP/ZjP5bbb7893/Ed35FSSn7/938/mzdvTpL85E/+ZK655pps3749z3/+8xueFACAhVBqrU3P8CQ7duyow8PDT3pu165dueqqqxqaaOH12q8HAKAblVLurLXuONtxlmQAAMAsBDMAAMxCMAMAwCy65qK/WmtKKU2PMW+dtma8Wzw2eTx33n8od9x3IHfcdyD3jI7H7yQAsBS6IphXr16dAwcO5OKLL+7qaK615sCBA1m9enXTo3S8x48ez/DINwP5i7sP5/hUzfJlJd9xxQX5iR1XZMVA9/63AAA077fbPK4rgnnLli3ZvXt39u/f3/Qo87Z69eps2bKl6TE6zuNHZ55BPpgvPPjoqUB+7pb1uemlT8+Ln35xXrj1wqxZ1RX/2QIAHa6ngnnFihXZvn1702OwgJ44euJJSyy+sPvRHDtRMyCQAYAO01aJlFJekeS/JBlI8qe11v902udvTPIHSR5qPfXHtdY/LaU8L8mfJFmX5ESS/1Br/dACzU4XeeLoiXz+gelAvv3r3xrIr3/JdCDvEMgAQIc5a5mUUgaSvDPJ9yXZnWSolHJrrXXnaYd+qNZ682nPPZ7kZ2qtXyulXJbkzlLKx2qtjy7E8HSHz9z7SG563505Mnk8A8tKnnP5+vzc9zw9L376Rdmx7aKsFcgAQAdrp1SuS3JvrfW+JCml3JLkVUlOD+ZvUWv96oyPHy6l7EuyIYlg7hOfufeR/Ox7h/K0i87Pb/7QVblWIAMAXaadcrk8yYMzHu9O8qIzHPfqUspLk3w1ya/VWme+JqWU65KsTPL1c5yVLvOZr38zlj/whhfnkrWrmh4JAGDOFurGJX+TZFut9blJ/iHJe2d+spRyaZL3JXldrXXq9BeXUm4qpQyXUoZ7YScMWrH8nqFccaFYBgC6WzvB/FCSK2Y83pJvXtyXJKm1Hqi1TrYe/mmSF578XCllXZKPJvmtWusdZ/oGtdZ31Vp31Fp3bNiwYS7z04Fu//qBU7H8wZvEMgDQ3doJ5qEkV5ZStpdSViZ5TZJbZx7QOoN80vVJdrWeX5nkL5P8t1rrRxZmZDrZHfcdcGYZAOgpZ13DXGs9Xkq5OcnHMr2t3LtrrXeXUt6WZLjWemuSXymlXJ/keJKDSW5svfwnk7w0ycWtreeS5MZa610L+8ugE9xx34G87s+GcvmF5+UDb3hxNgyKZQCg+5Vaa9MzPMmOHTvq8PBw02MwRzNj+YNiGQDoAqWUO2utO8523EJd9Ecf+2wrli+7YHU+8IYXiWUAoKcIZubls/cdyOveMx3LH7zpxdk4uLrpkQAAFpRg5px97hsH87r3DOXS9WIZAOhdgplz8rlvHMyNf/a5bF6/Oh98g1gGAHqXYGbOhka+Gcu3vOHF2bhOLAMAvUswMydDIwdz47vFMgDQPwQzbRtuxfKmdWIZAOgfgpm2DI8czGtbsfzBm8QyANA/BDNndef9T47lTWIZAOgjgplZ3Xn/wfzM//W5bBTLAECfEsw8pTvvP5TXvntoOpbfIJYBgP4kmDmj6Vj+XDYMrsoH3/DibF4vlgGA/iSY+RZDrQv8Llm7UiwDAH1PMPMkt3/9QF777s9l4+Cq3HLTd4plAKDvCWZO+dTXHsnr3vO5XH7Bebnl551ZBgBIkuVND0Bn+MQ9+/Lz77sz2y9Zk/e//kW5ZO2qpkcCAOgIgpl8fNfe/OL7P58rN63N+3/uRblwzcqmRwIA6BiWZPS5v//yaH7h/XfmqksH84HXv1gsAwCcRjD3sb/94sP55Q98Ps+5fH3e9/oXZf35K5oeCQCg41iS0af+6p8eyr/58F154dYL82evuy5rV/lPAQDgTFRSH/rInbvzpo98IS/aflHefeO1OX+l/wwAAJ6KUuozH/zcA/l3f/mlfPczLsl//ZkdOW/lQNMjAQB0NMHcR953+0h+56/vzsufuSH/x0+/MKtXiGUAgLMRzH3i3Z/6Rt72tzvzL67amHf+1AuyarlYBgBoh2DuA+/65NfzH2/7Sl7x7M35X294flYutzkKAEC7BHOPe+c/3ps/+Ng9eeVzL80f/cvnZcWAWAYAmAvB3KNqrflf/u+v5b98/Gv5sedfnj/48edmuVgGAJgzwdyDaq35z//jnrzzH7+eH3/hlrzj1c/NwLLS9FgAAF1JMPeYWmv+57/7St71yftyw3VX5D/86HOyTCwDAJwzwdxDaq1529/uzJ99eiQ/851b89YfebZYBgCYJ8HcI6amat5y65fz/jseyM9+9/b8ziuvSiliGQBgvgRzD5iaqvmtv/pyPvi5B/LzL3t63vyKZ4llAIAFIpi73MxY/uV/9oz8+vc/UywDACwg+4x1sampmt/+6+lY/qWXi2UAgMUgmLvUyVj+wGenY/lNPyCWAQAWg2DuQlNTNb/TiuVfFMsAAItKMHeZk7H85599IL/wsmfk34plAIBFJZi7SK3TW8edjOXfeIVYBgBYbIK5S9Q6fWb5/XdMbx0nlgEAloZg7gJPiuWX2mcZAGApCeYOV2vNW/767m/G8g+KZQCApSSYO9jJWH7fHffnJrEMANAIwdyhaq353VunY/kNL9me3xTLAACNEMwdqNaat956d/7b7dOx/O9+6CqxDADQEMHcYU7G8ntvvz+v/x6xDADQNMHcQWqt+b2/2Zn33n5/fu57tue3flgsAwA0TTB3iJOx/J7PjOTnvmd7flssAwB0BMHcAWbG8s9+t1gGAOgkgrlhtda87W+nY/l1370tv/NKsQwA0EkEc4NOxvKffXo6lt/yyqvFMgBAhxHMDam15u1/u0ssAwB0OMHckOH7D+Xdn/5GXvudW8UyAEAHE8wN+ex9B5Ikv/Z93y6WAQA6mGBuyNDIoXz7prW54PyVTY8CAMAsBHMDTkzVfP7+Q9mx7aKmRwEA4CwEcwO+MjqW8cnjuXbbhU2PAgDAWQjmBgyPHEqS7NjqDDMAQKcTzA0YGjmYS9evzpYLz2t6FAAAzkIwL7Faa4ZGDmbHtovsjgEA0AUE8xLbfeiJ7B2btH4ZAKBLCOYlNnz/wSTWLwMAdAvBvMSGRg5lcNXyPHPzYNOjAADQBsG8xIZHDuYFWy/MwDLrlwEAuoFgXkKPPn40X917xPplAIAuIpiX0J33t/Zfdoc/AICuIZiX0NDIoawYKPmOLRc0PQoAAG0SzEtoeORgrrl8fc5bOdD0KAAAtEkwL5GJYyfyxd2Hc63lGAAAXUUwL5EvPXQ4R09MZcdWF/wBAHQTwbxEhkZaNyxxhhkAoKu0FcyllFeUUu4ppdxbSnnzGT5/YyllfynlrtY/r5/xudeWUr7W+ue1Czl8Nxn6xsF828a1uWjNyqZHAQBgDpaf7YBSykCSdyb5viS7kwyVUm6tte487dAP1VpvPu21FyX53SQ7ktQkd7Zee2hBpu8SU1M1w/cfyiufe2nTowAAMEftnGG+Lsm9tdb7aq1Hk9yS5FVtfv0fSPIPtdaDrUj+hySvOLdRu9dX941nfOJ4dmy1HAMAoNu0E8yXJ3lwxuPdredO9+pSyhdLKR8ppVwxx9f2tKGR6RPqdsgAAOg+C3XR398k2VZrfW6mzyK/dy4vLqXcVEoZLqUM79+/f4FG6hzDIwezcXBVrrjovKZHAQBgjtoJ5oeSXDHj8ZbWc6fUWg/UWidbD/80yQvbfW3r9e+qte6ote7YsGFDu7N3jeGRQ7l220UppTQ9CgAAc9ROMA8lubKUsr2UsjLJa5LcOvOAUsrMq9muT7Kr9fHHknx/KeXCUsqFSb6/9VzfeOjRJ/LQo09kxzb7LwMAdKOz7pJRaz1eSrk506E7kOTdtda7SylvSzJca701ya+UUq5PcjzJwSQ3tl57sJTy9kxHd5K8rdZ6cBF+HR1ruLX/svXLAADd6azBnCS11tuS3Hbac2+Z8fFvJvnNp3jtu5O8ex4zdrXhkUNZs3Igz9o82PQoAACcA3f6W2RDIwfzgq0XZvmA32oAgG6k4hbR4SeO5Z694/ZfBgDoYoJ5EX3+gUOpNbnWBX8AAF1LMC+i4ZGDWb6s5HlPu6DpUQAAOEeCeRENjRzKsy9fn/NXtnVtJQAAHUgwL5LJ4ydy14OP5tqtlmMAAHQzwbxIvvzQ4Rw9PpUd9l8GAOhqgnmRDI0cShJ3+AMA6HKCeZEMjxzM0y9Zk0vWrmp6FAAA5kEwL4KpqZrh+w85uwwA0AME8yL4+v4jefTxY9YvAwD0AMG8CE6uX75WMAMAdD3BvAiGRw7mkrUrs+3i85seBQCAeRLMi2Do/oPZsfWilFKaHgUAgHkSzAts9PBEHjz4hAv+AAB6hGBeYMP3H0xi/TIAQK8QzAtseORQzl85kGdftq7pUQAAWACCeYENjRzM8592QZYP+K0FAOgFqm4BjU8cy649Y9mx1XIMAIBeIZgX0D898GimqvXLAAC9RDAvoKGRgxlYVvK8p13Q9CgAACwQwbyAhkYO5upL12XtquVNjwIAwAIRzAvk6PGp3PXgo/ZfBgDoMYJ5gdz98OFMHJuyfhkAoMcI5gUyPHIoSbJjqzPMAAC9RDAvkKGRg9l68fnZuG5106MAALCABPMCqLVm+P5D9l8GAOhBgnkB3PfIYzn42NFc64I/AICeI5gXwPDIwSTJDhf8AQD0HMG8AIZGDuWiNSvzjA1rmh4FAIAFJpgXwPDIwezYemFKKU2PAgDAAhPM87RvfCIjBx63/zIAQI8SzPN058n9l13wBwDQkwTzPA2NHMrqFcvy7MvWNz0KAACLQDDP09DIwTzviguycrnfSgCAXqTy5uHI5PHc/fBh65cBAHqYYJ6Hux54NFPV/ssAAL1MMM/D0MjBLCvJC552QdOjAACwSATzPAzffzDP2rwug6tXND0KAACLRDCfo2MnpvJPDzyaa20nBwDQ0wTzOdq1ZyyPHz1h/TIAQI8TzOdoqHXDEjtkAAD0NsF8joZHDuaKi87L5vWrmx4FAIBFJJjPQa01QyOHcu1WZ5cBAHqdYD4H9x94PI8cmbR+GQCgDwjmczA0cjBJ7JABANAHBPM5GB45lAvOX5FnbFjb9CgAACwywXwOhu4/mB1bL8yyZaXpUQAAWGSCeY4OHJnMffsfs34ZAKBPCOY5+ub+y9YvAwD0A8E8R8MjB7Ny+bJcc/n6pkcBAGAJCOY5Grr/UJ635YKsWj7Q9CgAACwBwTwHjx89nrsfOpwdlmMAAPQNwTwHdz34aI5P1Vzrgj8AgL4hmOdgeORQSklesNUZZgCAfiGY52Bo5GCeuWkw689b0fQoAAAsEcHcplpr7nrg0bzQ2WUAgL4imNu0+9ATGZ88nmdfZjs5AIB+IpjbdPfDY0mSqy9b1/AkAAAsJcHcpl17xrKsJM/cNNj0KAAALCHB3KZde8ay7ZI1OW+lG5YAAPQTwdymXaNjuepSyzEAAPqNYG7D2MSxPHjwiVwtmAEA+o5gbsNX9owniWAGAOhDgrkNu/ZM75BhSQYAQP8RzG3Y+fBYLlqzMpvWrWp6FAAAlphgbsP0BX+DKaU0PQoAAEtMMJ/F8RNTuWd0PFdtthwDAKAfCeazGDnwWCaPT1m/DADQpwTzWbglNgBAfxPMZ7Frz3hWDJQ8Y8PapkcBAKABbQVzKeUVpZR7Sin3llLePMtxry6l1FLKjtbjFaWU95ZSvlRK2VVK+c2FGnyp7Nozlm/bOJiVy/1vCwCAfnTWCiylDCR5Z5IfTHJ1khtKKVef4bjBJL+a5LMznv6JJKtqrc9J8sIkP19K2Tb/sZfOzj1jblgCANDH2jltel2Se2ut99Vajya5JcmrznDc25O8I8nEjOdqkjWllOVJzktyNMnY/EZeOo8cmcz+8clcdelg06MAANCQdoL58iQPzni8u/XcKaWUFyS5otb60dNe+5EkjyXZk+SBJP+51nrw3MddWifv8OcMMwBA/5r3wtxSyrIkf5jkjWf49HVJTiS5LMn2JG8spTz9DF/jplLKcClleP/+/fMdacG4JTYAAO0E80NJrpjxeEvruZMGk1yT5BOllJEkL05ya+vCv3+V5O9rrcdqrfuSfDrJjtO/Qa31XbXWHbXWHRs2bDi3X8ki2PnwWC5dvzoXrlnZ9CgAADSknWAeSnJlKWV7KWVlktckufXkJ2uth2utl9Rat9VatyW5I8n1tdbhTC/D+N4kKaWsyXRMf2WBfw2LZteecWeXAQD63FmDudZ6PMnNST6WZFeSD9da7y6lvK2Ucv1ZXv7OJGtLKXdnOrz/rNb6xfkOvRQmjp3I1/cfccEfAECfW97OQbXW25Lcdtpzb3mKY18+4+Mjmd5aruvcu+9Ijk/VXH3p+qZHAQCgQe7G8RR2nrrgzxlmAIB+Jpifwq49YzlvxUC2Xrym6VEAAGiQYH4Ku/aM5ZmbBzOwrDQ9CgAADRLMZ1Brzc6Hx3L1ZXbIAADod4L5DB4+PJGxieO2lAMAQDCfya6HT94S2wV/AAD9TjCfwc49YykleeZmZ5gBAPqdYD6DXXvGsvWi87N2VVvbVAMA0MME8xns2jNm/TIAAEkE87c4Mnk89x98XDADAJBEMH+Le0bHUmtytWAGACCC+Vvs3DOeJLnKHswAAEQwf4tde8aybvXyXLZ+ddOjAADQAQTzaU7e4a8Ut8QGAEAwP8mJqZp7Rsdd8AcAwCmCeYb7DzyWJ46dEMwAAJwimGfY1brgzw4ZAACcJJhn2LnncJYvK/m2jWubHgUAgA4hmGfYtWc8z9iwNqtXDDQ9CgAAHUIwzzB9S+zBpscAAKCDCOaWQ48dzZ7DE7naDUsAAJhBMLfs2jOWJHbIAADgSQRzy07BDADAGQjmll17xrNxcFUuWbuq6VEAAOgggrll554xZ5cBAPgWgjnJ0eNTuXefW2IDAPCtBHOSr+8/kmMnqi3lAAD4FoI5yc6Hpy/4e7Yt5QAAOI1gzvSWcquWL8u2i9c0PQoAAB1GMCfZNTqWZ24ezPIBvx0AADxZ3xdirTW79oznahf8AQBwBn0fzHvHJnPwsaN2yAAA4Iz6PpjdEhsAgNn0fTCfvCX2s2wpBwDAGQjmPWO54qLzsm71iqZHAQCgA/V9MO/aM5arNluOAQDAmfV1MD9x9ERGHnnM+mUAAJ5SXwfzPXvHM1WTq93hDwCAp9DXwXzyltj2YAYA4Kn0dTDv2jOWwVXLs+XC85oeBQCADtX3wfysSwdTSml6FAAAOlTfBvPUVM2uPWOWYwAAMKu+DeYHDz2ex46esEMGAACz6ttgdktsAADa0bfBvHPPeJaV5Jmb3RIbAICn1r/B/PBYnr5hbVavGGh6FAAAOljfBvOuPWOWYwAAcFZ9GcyHnziWhx59IlddajkGAACz68tgPnnBny3lAAA4G8EMAACz6NtgvnjNymwYXNX0KAAAdLg+DebxXH3ZOrfEBgDgrPoumI+fmMo9e8ftkAEAQFv6Lpjve+SxHD0+ZYcMAADa0nfB7JbYAADMRd8F886Hx7JyYFmesWFt06MAANAF+i+Y94zlyk1rs2Kg737pAACcg76rxl17XPAHAED7+iqY941P5JEjk25YAgBA2/oqmHftGU/igj8AANrXZ8HsltgAAMxN3wXz5Recl/Xnr2h6FAAAukRfBfPOh8fcsAQAgDnpm2CeOHYi9z3ymPXLAADMSd8E89f2HsmJqSqYAQCYk74JZhf8AQBwLvommHfuGcualQN52kXnNz0KAABdpK+C+ZmbB7NsWWl6FAAAukhfBHOtNbv2jOXqyyzHAABgbvoimHcfeiLjE8dd8AcAwJy1FcyllFeUUu4ppdxbSnnzLMe9upRSSyk7Zjz33FLK7aWUu0spXyqlrF6Iwefi5AV/ghkAgLlafrYDSikDSd6Z5PuS7E4yVEq5tda687TjBpP8apLPznhueZL3J/mfaq1fKKVcnOTYAs7fll17xlNK8qzNbloCAMDctHOG+bok99Za76u1Hk1yS5JXneG4tyd5R5KJGc99f5Iv1lq/kCS11gO11hPznHnOdu0Zy/aL1+T8lWf93wcAAPAk7QTz5UkenPF4d+u5U0opL0hyRa31o6e99tuT1FLKx0opny+l/Nt5TXuOdu4ZsxwDAIBzMu+L/kopy5L8YZI3nuHTy5N8T5Kfav37x0op//wMX+OmUspwKWV4//798x3pScYnjuWBg4/nqkstxwAAYO7aCeaHklwx4/GW1nMnDSa5JsknSikjSV6c5NbWhX+7k3yy1vpIrfXxJLclecHp36DW+q5a645a644NGzac26/kKdwzOp4ktpQDAOCctBPMQ0muLKVsL6WsTPKaJLee/GSt9XCt9ZJa67Za67YkdyS5vtY6nORjSZ5TSjm/dQHgy5Ls/NZvsXh22iEDAIB5OGsw11qPJ7k50/G7K8mHa613l1LeVkq5/iyvPZTp5RpDSe5K8vkzrHNeVLv2jOWC81dk87ol380OAIAe0Na2EbXW2zK9nGLmc295imNfftrj92d6a7lG7Nwznqs2r0spbokNAMDc9fSd/k5M1dwz6pbYAACcu54O5m888lgmjk1ZvwwAwDnr6WD+5i2xbSkHAMC56flgXjFQcuVGwQwAwLnp6WC+/+DjueLC87NyeU//MgEAWEQ9XZJ7D09kk+3kAACYh94O5vGJbFq3qukxAADoYj0bzLXW7B2bzKb1zjADAHDuejaYH338WI4en8qmQcEMAMC569lgHh2bSBJrmAEAmJeeDea9rWDevN4aZgAAzl3PBvO+sckkyUZLMgAAmIeeDeaTSzI22iUDAIB56Nlg3js2kYvWrMyq5QNNjwIAQBfr6WB2wR8AAPPVw8E86aYlAADMW88G8+jYRDY7wwwAwDz1ZDAfPzGVR45MZqNgBgBgnnoymPcfmUytcYYZAIB568lg3tvag9kaZgAA5qsng3n0sNtiAwCwMHoymPeNC2YAABZGTwbz6OGJLF9WcvGalU2PAgBAl+vJYN47NpmNg6uybFlpehQAALpcTwbzvvEJW8oBALAgejKYRw+7aQkAAAujJ4N579iELeUAAFgQPRfMTxw9kbGJ49m03hlmAADmr+eCee9Ya0u5QcEMAMD89Vwwj7aCebMzzAAALICeC+ZTZ5itYQYAYAH0cDA7wwwAwPz1YDBP5vyVA1m7annTowAA0AN6LphHx6b3YC7FXf4AAJi/ngvmfWMT2Wj9MgAAC6Tngnl0bML6ZQAAFkxPBXOtNXvHJt0WGwCABdNTwXz4iWM5enwqGwUzAAALpKeC+dRNSwQzAAALpKeCee/YZBI3LQEAYOH0VjAfdtMSAAAWVm8Fc2tJhm3lAABYKD0VzKNjE7lozcqsWj7Q9CgAAPSIngrmvWOT2Tjo7DIAAAunx4J5IpvXW78MAMDC6blg3jQomAEAWDg9E8zHT0zlkSOT2eQMMwAAC6hngvmRI0czVe3BDADAwuqZYD55lz9LMgAAWEg9E8wn92B20R8AAAupZ4J5n5uWAACwCHommEfHJjKwrOSSNYIZAICF0zPBfPKmJcuWlaZHAQCgh/RQME9k0zrrlwEAWFg9FsyWYwAAsLB6JphHD09kszPMAAAssJ4I5ieOnsjYxPFsFMwAACywngjmU3swC2YAABZYTwWzi/4AAFhoPRHMo6fu8ueiPwAAFlZPBPO+sckksYYZAIAF1xPBPDo2kfNWDGRw1fKmRwEAoMf0RDDvHZvI5vWrU4q7/AEAsLB6Ipj3tW6LDQAAC60ngnm0dYYZAAAWWtcHc621dVtswQwAwMLr+mA+/MSxTB6fEswAACyKrg/mva0t5Tats4YZAICF1/XBPOq22AAALKKuD2a3xQYAYDG1FcyllFeUUu4ppdxbSnnzLMe9upRSSyk7Tnv+aaWUI6WUX5/vwKfbe3g6mDdakgEAwCI4azCXUgaSvDPJDya5OskNpZSrz3DcYJJfTfLZM3yZP0zyd/Mb9cz2jk/kwvNXZNXygcX48gAA9Ll2zjBfl+TeWut9tdajSW5J8qozHPf2JO9IMjHzyVLKjyb5RpK75znrGY0enrQcAwCARdNOMF+e5MEZj3e3njullPKCJFfUWj/tjG9BAAAQw0lEQVR62vNrk/xGkt+b55xPad+4PZgBAFg8877or5SyLNNLLt54hk+/Nckf1VqPnOVr3FRKGS6lDO/fv39O33/08IQt5QAAWDTL2zjmoSRXzHi8pfXcSYNJrknyiVJKkmxOcmsp5fokL0ry46WU309yQZKpUspErfWPZ36DWuu7krwrSXbs2FHbHf74iak8cmTSlnIAACyadoJ5KMmVpZTtmQ7l1yT5Vyc/WWs9nOSSk49LKZ9I8uu11uEkL5nx/FuTHDk9lufjwGNHM1WTjYIZAIBFctYlGbXW40luTvKxJLuSfLjWencp5W2ts8iNGT3spiUAACyuds4wp9Z6W5LbTnvuLU9x7Muf4vm3znG2s3LTEgAAFltX3+nvVDCvd9EfAACLo8uDeTIDy0ouXiOYAQBYHF0dzKNjE9k4uCoDy0rTowAA0KO6Opj3jk3YIQMAgEXV9cG82U1LAABYRF0ezJN2yAAAYFF1bTBPHDuRw08cE8wAACyqrg1mezADALAUujaYT97lb5M1zAAALKKuDea945NJ3BYbAIDF1bXBvK+1JMO2cgAALKauDebRwxM5b8VA1q1e3vQoAAD0sK4N5r3jk9m0blVKcZc/AAAWT/cG8+EJO2QAALDoujeYxwUzAACLryuDudaa0cMT2bxeMAMAsLi6MpjHnjieyeNT2ThoD2YAABZXVwbzaGtLOWeYAQBYbF0ZzG6LDQDAUunKYD51hlkwAwCwyLoymE/e5W+DNcwAACyyrgzm0bGJXHD+iqxeMdD0KAAA9LiuDOa9Y5OWYwAAsCS6Mpj3jU1ko2AGAGAJdGUwj45NZPM665cBAFh8XRfMJ6Zq9o9P2lIOAIAl0XXB/MiRyUxVezADALA0ui6Y3bQEAICl1HXBPHrYTUsAAFg6XRfMe8cnkySbXPQHAMAS6L5gPjyRgWUlF68VzAAALL7uC+axiWxYuyoDy0rTowAA0Ae6LphHxyayab31ywAALI2uC+Z9Y5PZNGg5BgAAS6Prgnl0bMKWcgAALJmuCuaJYydy+Ilj2WxJBgAAS6Srgnnf2PSWchstyQAAYIl0VTCPtu7y5wwzAABLpauC2W2xAQBYaoIZAABm0XXBvHrFsqxbvbzpUQAA6BNdFcyjY5PZvG51SnGXPwAAlkZXBfPesYlstBwDAIAl1HXBvFkwAwCwhLommGut2Ts2kU3r7MEMAMDS6ZpgHnvieCaOTdkhAwCAJdU1wbx33JZyAAAsva4J5tHDghkAgKXXNcF88qYlLvoDAGApdU0w7xufTJJsdNEfAABLqGuCefTwRC44f0VWrxhoehQAAPpI1wTz3rGJbBq0HAMAgKXVXcG8XjADALC0uiiYJ7Np0PplAACWVlcE84mpmv1HJrPZGWYAAJZYVwTzgSOTOTFVs9GWcgAALLGuCOZRezADANCQrgjmvWPTezBvsgczAABLrCuC2RlmAACa0hXBvG9sIstKcvFaZ5gBAFhaXRHMo4cnsmFwVQaWlaZHAQCgz3RFMO8dn7QcAwCARnRFMO8bm7ClHAAAjeiKYB4dm3CGGQCARnR8ME8cO5FHHz9mSzkAABrR8cG879QezM4wAwCw9Do+mPeOT+/BLJgBAGhCxwfz6OHWTUvWC2YAAJZexwfz3tZd/jYNCmYAAJZeVwTz6hXLsu685U2PAgBAH+qCYJ7MpnWrU4q7/AEAsPTaCuZSyitKKfeUUu4tpbx5luNeXUqppZQdrcffV0q5s5Typda/v3euA46OTbjgDwCAxpw1mEspA0nemeQHk1yd5IZSytVnOG4wya8m+eyMpx9J8iO11uckeW2S9811wH2CGQCABrVzhvm6JPfWWu+rtR5NckuSV53huLcneUeSiZNP1Fr/qdb6cOvh3UnOK6W0fQeSWuv0GeZBNy0BAKAZ7QTz5UkenPF4d+u5U0opL0hyRa31o7N8nVcn+XytdbLd4cYmjmfi2JQt5QAAaMy8t54opSxL8odJbpzlmGdn+uzz9z/F529KclOSPO1pTzv1/L7WlnIbLckAAKAh7ZxhfijJFTMeb2k9d9JgkmuSfKKUMpLkxUlunXHh35Ykf5nkZ2qtXz/TN6i1vqvWuqPWumPDhg2nnh9tBfNmwQwAQEPaCeahJFeWUraXUlYmeU2SW09+stZ6uNZ6Sa11W611W5I7klxfax0upVyQ5KNJ3lxr/fRch9s7Nr16Y9M6a5gBAGjGWYO51no8yc1JPpZkV5IP11rvLqW8rZRy/VlefnOSb0vyllLKXa1/NrY73Km7/DnDDABAQ9paw1xrvS3Jbac995anOPblMz7+90n+/bkOt3dsIuvPW5HVKwbO9UsAAMC8dPSd/kYPT1i/DABAozo6mPeOT2aj9csAADSos4PZGWYAABrWscF8Yqpm/5FJF/wBANCojg3mA0cmc2KqZpO7/AEA0KCODeZTezAPWsMMAEBzOjaYR+3BDABAB+jYYD5505LNlmQAANCgjg3mfWMTWVaSi9esbHoUAAD6WMcG8+jYRDYMrsrygY4dEQCAPtCxNbp3zJZyAAA0r4ODeUIwAwDQuA4PZlvKAQDQrI4M5oljJ3Lo8WNuiw0AQOM6Mpj3j0/ftGSjYAYAoGEdGcwnb1riDDMAAE3ryGDe6y5/AAB0iI4M5tHDzjADANAZOjKY941PZtXyZVl33vKmRwEAoM91ZDCPHp7eg7mU0vQoAAD0uY4M5r1jE5ZjAADQEToymPeNT2ajm5YAANABOjKYRw87wwwAQGfouGA+UWueOHbClnIAAHSEjgvm48drkmTTesEMAEDzOi6Yj01NJUk2DVrDDABA8zovmE9MB/NmZ5gBAOgAHRjMrSUZ1jADANABOi6Yj5+YyvrzVmT1ioGmRwEAgM4L5mMnajbZgxkAgA7RgcE8ZTkGAAAdo+OC+fhUFcwAAHSMjgvm6TPMlmQAANAZOi6Yk7gtNgAAHaMjg3mjYAYAoEN0ZDA7wwwAQKfouGDeetH5efqGNU2PAQAASTowmNedtyKDq1c0PQYAACTpwGAGAIBOIpgBAGAWghkAAGYhmAEAYBaCGQAAZiGYAQBgFoIZAABmIZgBAGAWghkAAGYhmAEAYBaCGQAAZiGYAQBgFoIZAABmIZgBAGAWghkAAGYhmAEAYBaCGQAAZiGYAQBgFoIZAABmIZgBAGAWpdba9AxPUkoZT3JP03OQJLkkySNND4H3oYN4LzqD96FzeC86g/fh3G2ttW4420HLl2KSObqn1rqj6SFISinD3ovmeR86h/eiM3gfOof3ojN4HxafJRkAADALwQwAALPoxGB+V9MDcIr3ojN4HzqH96IzeB86h/eiM3gfFlnHXfQHAACdpBPPMAMAQMdoLJhLKa8opdxTSrm3lPLmM3z+35RSdpZSvlhK+XgpZWsTc/aDNt6LXyilfKmUclcp5VOllKubmLPXne19mHHcq0sptZTiiuhF0sbPxI2llP2tn4m7Simvb2LOXtfOz0Qp5Sdbf1fcXUr5wFLP2A/a+Hn4oxk/C18tpTzaxJz9oI334mmllH8spfxTq59+qIk5e1EjSzJKKQNJvprk+5LsTjKU5IZa684Zx/yzJJ+ttT5eSvnFJC+vtf7LJR+2x7X5XqyrtY61Pr4+yS/VWl/RxLy9qp33oXXcYJKPJlmZ5OZa6/BSz9rr2vyZuDHJjlrrzY0M2QfafB+uTPLhJN9baz1UStlYa93XyMA9qt0/m2Yc/6+TPL/W+rNLN2V/aPNn4l1J/qnW+ietk1u31Vq3NTFvr2nqDPN1Se6ttd5Xaz2a5JYkr5p5QK31H2utj7ce3pFkyxLP2C/aeS/GZjxck8TC94V31veh5e1J3pFkYimH6zPtvhcsrnbehzckeWet9VCSiOVFMdefhxuSfHBJJus/7bwXNcm61sfrkzy8hPP1tKaC+fIkD854vLv13FP5uSR/t6gT9a+23otSyi+XUr6e5PeT/MoSzdZPzvo+lFJekOSKWutHl3KwPtTun0+vbv1fnh8ppVyxNKP1lXbeh29P8u2llE+XUu4opfh/vhZe239ft5ZObk/y/yzBXP2onffirUl+upSyO8ltSf710ozW+zr+or9Syk8n2ZHkD5qepZ/VWt9Za31Gkt9I8ttNz9NvSinLkvxhkjc2PQtJkr9Jsq3W+twk/5DkvQ3P06+WJ7kyycszfWbzv5ZSLmh0ov72miQfqbWeaHqQPnZDkvfUWrck+aEk72v9/cE8NfWb+FCSmWdktrSee5JSyr9I8ltJrq+1Ti7RbP2mrfdihluS/OiiTtSfzvY+DCa5JsknSikjSV6c5FYX/i2Ks/5M1FoPzPgz6U+TvHCJZusn7fzZtDvJrbXWY7XWb2R6feeVSzRfv5jL3xGvieUYi6md9+LnMr2uP7XW25OsTnLJkkzX45oK5qEkV5ZStpdSVmb6h+zWmQeUUp6f5P/MdCxbl7Z42nkvZv4F9MNJvraE8/WLWd+HWuvhWusltdZtrQs47sj0z4aL/hZeOz8Tl854eH2SXUs4X7846/uQ5K8yfXY5pZRLMr1E476lHLIPtPM+pJTyrCQXJrl9iefrJ+28Fw8k+edJUkq5KtPBvH9Jp+xRy5v4prXW46WUm5N8LMlAknfXWu8upbwtyXCt9dZML8FYm+S/l1KS5IFa6/VNzNvL2nwvbm6d7T+W5FCS1zY3cW9q831gCbT5XvxKa8eY40kOJrmxsYF7VJvvw8eSfH8pZWeSE0neVGs90NzUvWcOfza9Jskt1d3QFk2b78UbM7006dcyfQHgjd6TheFOfwAAMAsLwQEAYBaCGQAAZiGYAQBgFoIZAABmIZgBAGAWghlgiZRSLiil/FLr45eXUv52Eb7HjaWUP57ja0Za+xif/vxbSym/vnDTAXQnwQywdC5I8ktzeUEpZWCRZgGgTYIZYOn8pyTPKKXcldbNmUopHymlfKWU8ueldZem1hnfd5RSPp/kJ0opzyil/H0p5c5Syv/XuqtaSik/UUr5cinlC6WUT874Ppe1jv9aKeX3Tz5ZSrmhlPKl1mvecaYBSym/VUr5ainlU0meuVi/EQDdpJE7/QH0qTcnuabW+rxSysuT/HWSZyd5OMmnk3x3kk+1jj1Qa31BkpRSPp7kF2qtXyulvCjJ/57ke5O8JckP1FofKqVcMOP7PC/J85NMJrmnlPK/ZfpOeO9I8sJM37Hzf5RSfrTW+lcnX1RKeWGm79j2vEz//fD5JHcu/G8DQHcRzADN+VytdXeStM46b8s3g/lDrefXJvmuJP+9dQI6SVa1/v3pJO8ppXw4yV/M+Lofr7Uebr1+Z5KtSS5O8ola6/7W83+e5KVJ/mrG616S5C9rrY+3jnFLdoAIZoAmTc74+ESe/GfyY61/L0vyaK31eae/uNb6C60zzj+c5M7WGeKzfV0A5sgaZoClM55kcC4vqLWOJflGKeUnkqRM+47Wx8+otX621vqWJPuTXDHLl/pckpeVUi5pXUh4Q5L/97RjPpnkR0sp55VSBpP8yFxmBehVzjoALJFa64FSyqdLKV9O8kSSvW2+9KeS/Ekp5beTrEhyS5IvJPmDUsqVSUqSj7ee+5Yz0a3vvaeU8uYk/9g6/qO11r8+7ZjPl1I+1Po6+5IMzfXXCNCLSq216RkAAKBjWZIBAACzEMwAADALwQwAALMQzAAAMAvBDAAAsxDMAAAwC8EMAACzEMwAADCL/x92/iThiWoxsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "- VGG19  \n",
    "Best IoU: 0.6604 at threshold: 0.540  \n",
    "epoch/sec: 173\n",
    "\n",
    "- ResNet  \n",
    "Best IoU: 0.5218 at threshold: 0.340    \n",
    "epoch/sec: 156\n",
    "\n",
    "- ResNet  \n",
    "Best IoU: 0.6889 at threshold: 0.840  \n",
    "epoch/sec: 238\n",
    "\n",
    ">:ResNetVGGResNet  \n",
    "- ResNetBest_IoUthreshold  \n",
    "- ResNet10\n",
    "- ImageNet\n",
    "- ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # model139\n",
    "    for layer in model.layers[:140]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "# print(model_depth.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/15\n",
      "3196/3196 [==============================] - 188s 59ms/step - loss: 0.6447 - my_iou_metric: 0.3869 - val_loss: 1.6865 - val_my_iou_metric: 0.0016\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00162, saving model to unet_resnet.h5\n",
      "Epoch 2/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.4967 - my_iou_metric: 0.5164 - val_loss: 1.5712 - val_my_iou_metric: 0.0014\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.00162\n",
      "Epoch 3/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.4306 - my_iou_metric: 0.5312 - val_loss: 2.4263 - val_my_iou_metric: 0.0187\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.00162 to 0.01866, saving model to unet_resnet.h5\n",
      "Epoch 4/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.3783 - my_iou_metric: 0.5858 - val_loss: 2.3194 - val_my_iou_metric: 0.0187\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.01866\n",
      "Epoch 5/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.3370 - my_iou_metric: 0.6249 - val_loss: 2.3024 - val_my_iou_metric: 0.3831\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.01866 to 0.38308, saving model to unet_resnet.h5\n",
      "Epoch 6/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.3158 - my_iou_metric: 0.6536 - val_loss: 2.8515 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.38308 to 0.38930, saving model to unet_resnet.h5\n",
      "Epoch 7/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.2690 - my_iou_metric: 0.6743 - val_loss: 2.1750 - val_my_iou_metric: 0.3433\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 8/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.2275 - my_iou_metric: 0.7048 - val_loss: 2.9972 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 9/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.2233 - my_iou_metric: 0.7133 - val_loss: 2.6880 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 10/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.1925 - my_iou_metric: 0.7388 - val_loss: 2.7694 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 11/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.1739 - my_iou_metric: 0.7472 - val_loss: 2.2375 - val_my_iou_metric: 0.2898\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.38930\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.1490 - my_iou_metric: 0.7668 - val_loss: 2.2415 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 13/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.1140 - my_iou_metric: 0.8005 - val_loss: 2.9728 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 14/15\n",
      "3196/3196 [==============================] - 173s 54ms/step - loss: 0.1080 - my_iou_metric: 0.8009 - val_loss: 2.5920 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.38930\n",
      "Epoch 15/15\n",
      "3196/3196 [==============================] - 172s 54ms/step - loss: 0.0973 - my_iou_metric: 0.8013 - val_loss: 2.9944 - val_my_iou_metric: 0.3893\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.38930\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "epochs = 15  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_res = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred_res = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds_res)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:49<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred_res > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5218 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>3.379295e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>5.217662e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold           iou\n",
       "count  35.000000  3.500000e+01\n",
       "mean    0.540000  5.217662e-01\n",
       "std     0.204939  3.379295e-16\n",
       "min     0.200000  5.217662e-01\n",
       "25%     0.370000  5.217662e-01\n",
       "50%     0.540000  5.217662e-01\n",
       "75%     0.710000  5.217662e-01\n",
       "max     0.880000  5.217662e-01"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c9c17b898>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    \n",
    "    # model\n",
    "    for layer in model.layers[39:172]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/15\n",
      "3196/3196 [==============================] - 220s 69ms/step - loss: 0.8052 - my_iou_metric: 0.3539 - val_loss: 0.8766 - val_my_iou_metric: 0.4244\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.42438, saving model to unet_resnet.h5\n",
      "Epoch 2/15\n",
      "3196/3196 [==============================] - 202s 63ms/step - loss: 0.6228 - my_iou_metric: 0.4629 - val_loss: 0.8411 - val_my_iou_metric: 0.4067\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.42438\n",
      "Epoch 3/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.5445 - my_iou_metric: 0.5062 - val_loss: 0.8028 - val_my_iou_metric: 0.3287\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.42438\n",
      "Epoch 4/15\n",
      "3196/3196 [==============================] - 203s 64ms/step - loss: 0.5154 - my_iou_metric: 0.5394 - val_loss: 0.7869 - val_my_iou_metric: 0.3414\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.42438\n",
      "Epoch 5/15\n",
      "3196/3196 [==============================] - 203s 64ms/step - loss: 0.4761 - my_iou_metric: 0.5564 - val_loss: 0.7792 - val_my_iou_metric: 0.4189\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.42438\n",
      "Epoch 6/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.4763 - my_iou_metric: 0.5521 - val_loss: 1.2749 - val_my_iou_metric: 0.4076\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.42438\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.4285 - my_iou_metric: 0.5770 - val_loss: 1.3620 - val_my_iou_metric: 0.4854\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.42438 to 0.48545, saving model to unet_resnet.h5\n",
      "Epoch 8/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.3889 - my_iou_metric: 0.5948 - val_loss: 0.9016 - val_my_iou_metric: 0.5199\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.48545 to 0.51990, saving model to unet_resnet.h5\n",
      "Epoch 9/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.3790 - my_iou_metric: 0.6115 - val_loss: 0.9766 - val_my_iou_metric: 0.5555\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.51990 to 0.55547, saving model to unet_resnet.h5\n",
      "Epoch 10/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.3704 - my_iou_metric: 0.6170 - val_loss: 0.8585 - val_my_iou_metric: 0.5280\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.55547\n",
      "Epoch 11/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.3572 - my_iou_metric: 0.6204 - val_loss: 0.6610 - val_my_iou_metric: 0.6006\n",
      "\n",
      "Epoch 00011: val_my_iou_metric improved from 0.55547 to 0.60062, saving model to unet_resnet.h5\n",
      "Epoch 12/15\n",
      "3196/3196 [==============================] - 203s 63ms/step - loss: 0.3454 - my_iou_metric: 0.6419 - val_loss: 1.0479 - val_my_iou_metric: 0.5485\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.60062\n",
      "Epoch 13/15\n",
      "3196/3196 [==============================] - 202s 63ms/step - loss: 0.3307 - my_iou_metric: 0.6289 - val_loss: 0.9387 - val_my_iou_metric: 0.5424\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.60062\n",
      "Epoch 14/15\n",
      "3196/3196 [==============================] - 202s 63ms/step - loss: 0.3174 - my_iou_metric: 0.6533 - val_loss: 0.6298 - val_my_iou_metric: 0.6053\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.60062 to 0.60535, saving model to unet_resnet.h5\n",
      "Epoch 15/15\n",
      "3196/3196 [==============================] - 202s 63ms/step - loss: 0.3072 - my_iou_metric: 0.6550 - val_loss: 1.2912 - val_my_iou_metric: 0.4994\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.60535\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "epochs = 15  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:48<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "val_preds_res = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred_res = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds_res)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))\n",
    "\n",
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred_res > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5657 at threshold: 0.660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.556230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.523383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.553545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.559950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.563371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.565672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.556230\n",
       "std     0.204939   0.010264\n",
       "min     0.200000   0.523383\n",
       "25%     0.370000   0.553545\n",
       "50%     0.540000   0.559950\n",
       "75%     0.710000   0.563371\n",
       "max     0.880000   0.565672"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c0ef84e80>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:48<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# VGG + ResNet\n",
    "pre = (val_preds_res + val_preds_vgg)/2\n",
    "y_val_pre = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), pre)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))\n",
    "\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pre > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6760 at threshold: 0.480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.615547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.048001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.556095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.570833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.592662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.668408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.675995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.615547\n",
       "std     0.204939   0.048001\n",
       "min     0.200000   0.556095\n",
       "25%     0.370000   0.570833\n",
       "50%     0.540000   0.592662\n",
       "75%     0.710000   0.668408\n",
       "max     0.880000   0.675995"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best IoU: 0.5657 at threshold: 0.660ResNet)\n",
    "- Best IoU: 0.6604 at threshold: 0.540VGG  \n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c6a310a58>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
