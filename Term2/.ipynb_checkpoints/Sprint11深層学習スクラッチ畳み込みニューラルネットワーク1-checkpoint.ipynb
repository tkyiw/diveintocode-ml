{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。  \n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$$\n",
    "\n",
    "$a_i$ : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "\n",
    "$$w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s}$$\n",
    "$$b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}$$\n",
    "$$\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 $j-s<0$ または $j-s>N_{out}-1$ のとき $\\frac{\\partial L}{\\partial a_{(j-s)}} =0$ です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    '''\n",
    "    1次元畳み込み層のクラス\n",
    "    '''\n",
    "    def forward(self, x, w, b):\n",
    "        a = []\n",
    "        for i in range(len(w) - 1):\n",
    "            a.append((x[i:i+len(w)] @ w) + b[0])\n",
    "        return np.array(a)\n",
    "    \n",
    "    def backward(self, x, w, da):\n",
    "        db = np.sum(da)\n",
    "\n",
    "        dw = []\n",
    "        for i in range(len(w)):\n",
    "            dw.append(da @ x[i:i+len(da)])\n",
    "        dw = np.array(dw)\n",
    "\n",
    "        dx = []\n",
    "        new_w = np.insert(w[::-1], 0, 0)\n",
    "        new_w = np.append(new_w, 0)\n",
    "        for i in range(len(new_w)-1):\n",
    "            dx.append(new_w[i:i+len(da)] @ da)\n",
    "        dx = np.array(dx[::-1])\n",
    "        return db, dw, dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "\n",
    "$$N_{out} =  \\frac{N_{in}+2P-F}{S} + 1$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(n_in, P, F, S):\n",
    "    n_out = int((n_in + 2*P - F) / S + 1)\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "da = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 50]\n",
      "30\n",
      "[ 50  80 110]\n",
      "[ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "sc = SimpleConv1d()\n",
    "db, dw, dx = sc.backward(x, w, da)\n",
    "print(sc.forward(x, w, b))\n",
    "print(db)\n",
    "print(dw)\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes(C, F, W):\n",
    "    li = []\n",
    "    for i in range(C):\n",
    "        li.append(list(range(i, F+i)))\n",
    "        \n",
    "    return np.array(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, w, b):\n",
    "    FN, C, F = w.shape\n",
    "    C, W = x.shape\n",
    "    out_w = out_size(W, 0, F, 1)  \n",
    "    a = np.zeros((FN, out_w))\n",
    "    ind = indexes(C, F, W)\n",
    "    for i in range(FN):\n",
    "        for j in range(C):\n",
    "            a[i, j] = np.sum(x[j, ind] @ w[i, j]) + b[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = forward(x, w, b)\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, w, da):\n",
    "    FN, C, F = w.shape\n",
    "    C, W = x.shape\n",
    "    \n",
    "    db = np.sum(da)\n",
    "\n",
    "    dw = []\n",
    "    for i in da:\n",
    "        for j in x:\n",
    "            for k in range(len(w)):\n",
    "                dw.append(i @ j[k:k+len(i)])\n",
    "    dw = np.array(dw).reshape(FN, C, F)\n",
    "\n",
    "    li = []\n",
    "    for i in w:\n",
    "        for j in range(len(i)):\n",
    "            new_w = np.insert(i[j][::-1], 0, 0)\n",
    "            new_w = np.append(new_w, 0).tolist()\n",
    "            li.append(new_w)\n",
    "    li = np.array(li).reshape(3, 2, 5)\n",
    "    \n",
    "    dx = np.zeros(x.shape)\n",
    "    for i, j in zip(da, li):\n",
    "        for k in range(len(j)):\n",
    "            ww = j[k]\n",
    "            dxl = []\n",
    "            for l in range(len(ww)-1):\n",
    "                dxl.append(ww[l:l+len(i)] @ i)\n",
    "            dx[k] += dxl[::-1]\n",
    "    \n",
    "    return dw, dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw, dx = backward(x, w, da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 60.,  98., 136.],\n",
       "        [ 98., 136., 174.]],\n",
       "\n",
       "       [[ 63., 103., 143.],\n",
       "        [103., 143., 183.]],\n",
       "\n",
       "       [[ 66., 108., 150.],\n",
       "        [108., 150., 192.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 51., 120., 120.,  69.],\n",
       "       [ 51., 120., 120.,  69.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    def __init__(self, FN, C, F, sigma=0.1, lr=0.1):\n",
    "        self.sigma = sigma\n",
    "        self.lr = lr\n",
    "        self.w = self.sigma * np.random.randn(FN, C, F)\n",
    "        self.b = self.sigma * np.random.randn(FN, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        FN, C, F = self.w.shape\n",
    "        C, W = self.x.shape\n",
    "        out_w = self.out_size(W, 0, F, 1)\n",
    "        a = np.zeros((FN, out_w))\n",
    "        ind = self.indexes(C, F, W)\n",
    "        for i in range(FN):\n",
    "            for j in range(C):\n",
    "                a[i, j] = np.sum(self.x[j, ind] @ self.w[i, j]) + self.b[i]\n",
    "        return a\n",
    "    \n",
    "    def backward(self, loss):\n",
    "        FN, C, F = self.w.shape\n",
    "        C, W = self.x.shape\n",
    "\n",
    "        self.db = np.sum(loss)\n",
    "\n",
    "        dw = []\n",
    "        for i in loss:\n",
    "            for j in self.x:\n",
    "                for k in range(FN):\n",
    "                    dw.append(i @ j[k:k+len(i)])\n",
    "        self.dw = np.array(dw).reshape(FN, C, -1)\n",
    "\n",
    "        li = []\n",
    "        for i in self.w:\n",
    "            for j in range(len(i)):\n",
    "                new_w = np.insert(i[j][::-1], 0, 0)\n",
    "                new_w = np.append(new_w, 0).tolist()\n",
    "                li.append(new_w)\n",
    "        li = np.array(li).reshape(FN, C, -1)\n",
    "\n",
    "        self.dx = np.zeros(self.x.shape)\n",
    "        for i, j in zip(loss, li):\n",
    "            for k in range(len(j)):\n",
    "                ww = j[k]\n",
    "                dxl = []\n",
    "                for l in range(len(ww)-len(i)+1):\n",
    "                    dxl.append(ww[l:l+len(i)] @ i)\n",
    "                self.dx[k] += dxl[::-1]\n",
    "                \n",
    "        self = self.update(self)\n",
    "\n",
    "        return self.dx\n",
    "    \n",
    "    def indexes(self, C, F, W):\n",
    "        li = []\n",
    "        for i in range(C):\n",
    "            li.append(list(range(i, F+i)))\n",
    "\n",
    "        return np.array(li)\n",
    "    \n",
    "    def out_size(self, n_in, P, F, S):\n",
    "        n_out = int((n_in + 2*P - F) / S + 1)\n",
    "        return n_out\n",
    "    \n",
    "    def update(self, layer):\n",
    "        layer.w -= self.lr * layer.dw\n",
    "        layer.b -= self.lr * layer.db\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49507873,  0.3970675 ],\n",
       "       [-0.69675105, -0.31330106],\n",
       "       [ 1.42640565,  1.05523178]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes = Conv1d(3, 2, 3)\n",
    "tes.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36485051, 4.92383577, 6.3469198 , 0.41924533],\n",
       "       [1.61821077, 3.38967622, 2.47823585, 1.07534866]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes.backward(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b.astype('float64')\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        # パラメータ更新\n",
    "        self.update()\n",
    "\n",
    "        return dx\n",
    "    \n",
    "    def update(self):\n",
    "        self.W -= 0.05 * self.dW\n",
    "        self.b -= 0.05 * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        # 最適化手法\n",
    "        self.optimizer = optimizer\n",
    "        # AdaGradの初期値\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.Z = X\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "        \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        _ = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    '''\n",
    "    AdaGradによる最適化\n",
    "    '''\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr # 学習率\n",
    "    \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7 # 0で除算してしまうのを防ぐための値\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    シグモイド関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    '''\n",
    "    ハイパボリックタンジェント関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    '''\n",
    "    ReLU関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    '''\n",
    "    ソフトマックス関数と交差エントロピー誤差\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, Z, y):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "        y : ラベル  ndarray, shape (batch_size,)\n",
    "            入力\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        loss : 交差エントロピー誤差\n",
    "        \"\"\"\n",
    "        dA = Z - y\n",
    "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out = x.reshape(N, -1)\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout.reshape(self.x.shape)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier():\n",
    "    \"\"\"\n",
    "    3層からなるニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch=1, optimizer=AdaGrad, initializer=HeInitializer, activater=Relu, verbose=False,):\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = 60 # バッチサイズ\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        self.sigma = 0.02 # ガウス分布の標準偏差\n",
    "        self.lr = 0.05 # 学習率\n",
    "        self.epoch = epoch # エポック数\n",
    "        self.optimizer = optimizer # 最適化手法\n",
    "        self.initializer = initializer # 初期化方法\n",
    "        self.activater = activater # 活性化関数\n",
    "        self.FN = 30\n",
    "        self.C = 1\n",
    "        self.FH = 1\n",
    "        self.FW = 5\n",
    "        self.pad = 0\n",
    "        self.stride = 1\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.loss_train = [] # 学習データのloss記録用\n",
    "        self.loss_val = [] # 検証データのloss記録用\n",
    "        \n",
    "        # 全結合層へ流れるnode数を取得\n",
    "        out_h, out_w = self.out_size(1, 784, self.pad, self.FH, self.FW, self.stride)\n",
    "        fc_nodes = self.FN * out_h * out_w\n",
    "        \n",
    "        # 最適化手法を選択\n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        \n",
    "        # 重みとバイアスの初期値\n",
    "        w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
    "        b = self.sigma * np.random.randn(self.FN,)\n",
    "        \n",
    "        # インスタンス化\n",
    "        self.cv = Conv1d(w, b)\n",
    "        self.activation_cv = self.activater()\n",
    "        self.fl = Flatten()\n",
    "        self.FC = FC(fc_nodes, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation_fc = SoftmaxWithLoss()\n",
    "        \n",
    "        # 学習\n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "\n",
    "                # フォワード\n",
    "                A1 = self.cv.forward(mini_X)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "                F1 = self.fl.forward(Z1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.activation_fc.forward(A2)\n",
    "\n",
    "                # バックワード\n",
    "                dA2, loss = self.activation_fc.backward(Z2, mini_y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dF1 = self.fl.backward(dZ2)\n",
    "                dA1 = self.activation_cv.backward(dF1)\n",
    "                dZ1 = self.cv.backward(dA1)\n",
    "            \n",
    "            # エポックごとに交差エントロピー誤差を記録\n",
    "            if self.verbose:\n",
    "                A1 = self.cv.forward(X)\n",
    "                Z1 = self.activation_cv.forward(A1)\n",
    "                F1 = self.fl.forward(Z1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.activation_fc.forward(A2)  \n",
    "                self.loss_train.append(self.activation_fc.backward(Z2, y)[1])\n",
    "                \n",
    "                if X_val is not None:\n",
    "                    A1 = self.cv.forward(X_val)\n",
    "                    Z1 = self.activation_cv.forward(A1)\n",
    "                    F1 = self.fl.forward(Z1)\n",
    "                    A2 = self.FC.forward(F1)\n",
    "                    Z2 = self.activation_fc.forward(A2)         \n",
    "                    self.loss_val.append(self.activation_fc.backward(Z2, y_val)[1])\n",
    "                    \n",
    "    def out_size(self, H, W, P, FH, FW, S):\n",
    "        out_h = (H + 2 * P - FH) // S + 1\n",
    "        out_w = (W + 2 * P - FW) // S + 1\n",
    "        return out_h, out_w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.cv.forward(X)\n",
    "        Z1 = self.activation_cv.forward(A1)\n",
    "        F1 = self.fl.forward(Z1)\n",
    "        A2 = self.FC.forward(F1)\n",
    "        Z2 = self.activation_fc.forward(A2)\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# データセット読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# # 標準化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# # チャネル数の軸を追加\n",
    "X_train = X_train[:, np.newaxis, np.newaxis, :]\n",
    "X_test = X_test[:, np.newaxis, np.newaxis, :]\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 24s, sys: 10min 27s, total: 17min 51s\n",
      "Wall time: 33min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9373333333333334"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cnn = Scratch1dCNNClassifier(epoch=5, verbose=True)\n",
    "cnn.fit(X_train, y_train_one_hot, X_val, y_test_one_hot)\n",
    "\n",
    "pred = cnn.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学習曲線\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('epoch number')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(list(range(1, cnn.epoch+1)), cnn.loss_train, label='train')\n",
    "plt.plot(list(range(1, cnn.epoch+1)), cnn.loss_val, label='test')\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, cnn.epoch+1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">学習を続ければもう少し精度が出せそうだが、DNNではもっと短時間で良い精度が出ていた。  \n",
    "1次元では畳み込みの強みを発揮できなかった。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
